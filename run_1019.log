

Python 3.12.5
['▁<', '|', 'endo', 'f', 'text', '|', '>']
[39, 19, 37, 35, 38, 19, 40]
['▁Before', '▁we', '▁pro', 'ce', 'ed', '▁any', '▁further', ',', '▁hear', '▁me', '▁speak', '.']
torch.Size([512, 128]) torch.Size([512, 128])
The <|endoftext|> id is : 1
total params: 12,597,504
model size: 48.243MB
Training on cuda.
Epoch 1/2:
Step 1/953240 - LR:0.0016 - train_loss: 8.486Step 11/953240 - LR:0.0016 - train_loss: 5.989Step 21/953240 - LR:0.0017 - train_loss: 5.944Step 31/953240 - LR:0.0016 - train_loss: 5.922Step 41/953240 - LR:0.0017 - train_loss: 5.905Step 51/953240 - LR:0.0016 - train_loss: 5.878Step 61/953240 - LR:0.0017 - train_loss: 5.805Step 71/953240 - LR:0.0016 - train_loss: 5.497Step 81/953240 - LR:0.0017 - train_loss: 5.335Step 91/953240 - LR:0.0016 - train_loss: 5.216Step 101/953240 - LR:0.0016 - train_loss: 5.155Step 111/953240 - LR:0.0016 - train_loss: 5.139Step 121/953240 - LR:0.0017 - train_loss: 5.215Step 131/953240 - LR:0.0016 - train_loss: 5.096Step 141/953240 - LR:0.0017 - train_loss: 5.044Step 151/953240 - LR:0.0016 - train_loss: 5.017Step 161/953240 - LR:0.0017 - train_loss: 5.609Step 171/953240 - LR:0.0016 - train_loss: 5.395Step 181/953240 - LR:0.0017 - train_loss: 5.248Step 191/953240 - LR:0.0016 - train_loss: 5.134Step 201/953240 - LR:0.0016 - train_loss: 5.047Step 211/953240 - LR:0.0016 - train_loss: 5.030Step 221/953240 - LR:0.0016 - train_loss: 4.987Step 231/953240 - LR:0.0016 - train_loss: 5.015Step 241/953240 - LR:0.0017 - train_loss: 4.950Step 251/953240 - LR:0.0016 - train_loss: 4.902Step 261/953240 - LR:0.0017 - train_loss: 4.910Step 271/953240 - LR:0.0016 - train_loss: 4.806Step 281/953240 - LR:0.0017 - train_loss: 4.797Step 291/953240 - LR:0.0016 - train_loss: 4.767Step 301/953240 - LR:0.0017 - train_loss: 4.774Step 311/953240 - LR:0.0016 - train_loss: 5.137Step 321/953240 - LR:0.0017 - train_loss: 4.840Step 331/953240 - LR:0.0016 - train_loss: 4.870Step 341/953240 - LR:0.0017 - train_loss: 4.723Step 351/953240 - LR:0.0016 - train_loss: 4.729Step 361/953240 - LR:0.0017 - train_loss: 4.659Step 371/953240 - LR:0.0016 - train_loss: 4.731Step 381/953240 - LR:0.0017 - train_loss: 4.654Step 391/953240 - LR:0.0016 - train_loss: 4.597Step 401/953240 - LR:0.0017 - train_loss: 4.574Step 411/953240 - LR:0.0016 - train_loss: 4.537Step 421/953240 - LR:0.0017 - train_loss: 4.496Step 431/953240 - LR:0.0016 - train_loss: 4.800Step 441/953240 - LR:0.0017 - train_loss: 4.562Step 451/953240 - LR:0.0016 - train_loss: 4.853Step 461/953240 - LR:0.0017 - train_loss: 4.492Step 471/953240 - LR:0.0016 - train_loss: 4.457Step 481/953240 - LR:0.0017 - train_loss: 4.410Step 491/953240 - LR:0.0016 - train_loss: 4.454Step 501/953240 - LR:0.0017 - train_loss: 4.386Step 511/953240 - LR:0.0016 - train_loss: 4.420Step 521/953240 - LR:0.0017 - train_loss: 4.353Step 531/953240 - LR:0.0016 - train_loss: 4.389Step 541/953240 - LR:0.0017 - train_loss: 4.306Step 551/953240 - LR:0.0016 - train_loss: 4.321Step 561/953240 - LR:0.0017 - train_loss: 4.225Step 571/953240 - LR:0.0016 - train_loss: 4.353Step 581/953240 - LR:0.0016 - train_loss: 4.313Step 591/953240 - LR:0.0016 - train_loss: 4.205Step 601/953240 - LR:0.0016 - train_loss: 4.159Step 611/953240 - LR:0.0016 - train_loss: 4.296Step 621/953240 - LR:0.0016 - train_loss: 4.180Step 631/953240 - LR:0.0016 - train_loss: 4.352Step 641/953240 - LR:0.0017 - train_loss: 4.158Step 651/953240 - LR:0.0016 - train_loss: 4.130Step 661/953240 - LR:0.0017 - train_loss: 4.054Step 671/953240 - LR:0.0016 - train_loss: 4.028Step 681/953240 - LR:0.0017 - train_loss: 4.019Step 691/953240 - LR:0.0016 - train_loss: 4.053Step 701/953240 - LR:0.0017 - train_loss: 4.005Step 711/953240 - LR:0.0016 - train_loss: 4.152Step 721/953240 - LR:0.0017 - train_loss: 3.978Step 731/953240 - LR:0.0016 - train_loss: 4.027Step 741/953240 - LR:0.0017 - train_loss: 3.945Step 751/953240 - LR:0.0016 - train_loss: 3.975Step 761/953240 - LR:0.0017 - train_loss: 3.906Step 771/953240 - LR:0.0016 - train_loss: 3.847Step 781/953240 - LR:0.0016 - train_loss: 3.831Step 791/953240 - LR:0.0016 - train_loss: 4.175Step 801/953240 - LR:0.0017 - train_loss: 3.926Step 811/953240 - LR:0.0016 - train_loss: 3.948Step 821/953240 - LR:0.0017 - train_loss: 3.853Step 831/953240 - LR:0.0016 - train_loss: 4.017Step 841/953240 - LR:0.0017 - train_loss: 3.858Step 851/953240 - LR:0.0016 - train_loss: 3.994Step 861/953240 - LR:0.0017 - train_loss: 3.905Step 871/953240 - LR:0.0016 - train_loss: 3.829Step 881/953240 - LR:0.0017 - train_loss: 3.779Step 891/953240 - LR:0.0016 - train_loss: 3.761Step 901/953240 - LR:0.0017 - train_loss: 3.753Step 911/953240 - LR:0.0016 - train_loss: 3.846Step 921/953240 - LR:0.0017 - train_loss: 3.718Step 931/953240 - LR:0.0016 - train_loss: 3.910Step 941/953240 - LR:0.0017 - train_loss: 3.800Step 951/953240 - LR:0.0016 - train_loss: 3.833Step 961/953240 - LR:0.0017 - train_loss: 3.744Step 971/953240 - LR:0.0016 - train_loss: 3.713Step 981/953240 - LR:0.0017 - train_loss: 3.685Step 991/953240 - LR:0.0016 - train_loss: 3.751Step 1001/953240 - LR:0.0017 - train_loss: 3.655Step 1011/953240 - LR:0.0016 - train_loss: 3.686Step 1021/953240 - LR:0.0017 - train_loss: 3.642Step 1031/953240 - LR:0.0016 - train_loss: 3.777Step 1041/953240 - LR:0.0017 - train_loss: 3.674Step 1051/953240 - LR:0.0016 - train_loss: 3.760Step 1061/953240 - LR:0.0017 - train_loss: 3.661Step 1071/953240 - LR:0.0016 - train_loss: 3.714Step 1081/953240 - LR:0.0017 - train_loss: 3.624Step 1091/953240 - LR:0.0016 - train_loss: 3.718Step 1101/953240 - LR:0.0017 - train_loss: 3.648Step 1111/953240 - LR:0.0016 - train_loss: 3.576Step 1121/953240 - LR:0.0017 - train_loss: 3.554Step 1131/953240 - LR:0.0016 - train_loss: 3.681Step 1141/953240 - LR:0.0017 - train_loss: 3.586Step 1151/953240 - LR:0.0016 - train_loss: 3.736Step 1161/953240 - LR:0.0017 - train_loss: 3.609Step 1171/953240 - LR:0.0016 - train_loss: 3.592Step 1181/953240 - LR:0.0017 - train_loss: 3.519Step 1191/953240 - LR:0.0016 - train_loss: 3.692Step 1201/953240 - LR:0.0017 - train_loss: 3.561Step 1211/953240 - LR:0.0016 - train_loss: 3.557Step 1221/953240 - LR:0.0017 - train_loss: 3.506Step 1231/953240 - LR:0.0016 - train_loss: 3.592Step 1241/953240 - LR:0.0017 - train_loss: 3.479Step 1251/953240 - LR:0.0016 - train_loss: 3.499Step 1261/953240 - LR:0.0017 - train_loss: 3.463Step 1271/953240 - LR:0.0016 - train_loss: 3.541Step 1281/953240 - LR:0.0017 - train_loss: 3.444Step 1291/953240 - LR:0.0016 - train_loss: 3.548Step 1301/953240 - LR:0.0017 - train_loss: 3.434Step 1311/953240 - LR:0.0016 - train_loss: 3.589Step 1321/953240 - LR:0.0017 - train_loss: 3.444Step 1331/953240 - LR:0.0016 - train_loss: 3.523Step 1341/953240 - LR:0.0016 - train_loss: 3.461Step 1351/953240 - LR:0.0016 - train_loss: 3.556Step 1361/953240 - LR:0.0017 - train_loss: 3.476Step 1371/953240 - LR:0.0016 - train_loss: 3.467Step 1381/953240 - LR:0.0017 - train_loss: 3.446Step 1391/953240 - LR:0.0016 - train_loss: 3.574Step 1401/953240 - LR:0.0017 - train_loss: 3.430Step 1411/953240 - LR:0.0016 - train_loss: 3.502Step 1421/953240 - LR:0.0016 - train_loss: 3.424Step 1431/953240 - LR:0.0016 - train_loss: 3.391Step 1441/953240 - LR:0.0017 - train_loss: 3.303Step 1451/953240 - LR:0.0016 - train_loss: 3.401Step 1461/953240 - LR:0.0017 - train_loss: 3.350Step 1471/953240 - LR:0.0016 - train_loss: 3.435Step 1481/953240 - LR:0.0017 - train_loss: 3.357Step 1491/953240 - LR:0.0016 - train_loss: 3.451Step 1501/953240 - LR:0.0017 - train_loss: 3.354Step 1511/953240 - LR:0.0016 - train_loss: 3.403Step 1521/953240 - LR:0.0017 - train_loss: 3.352Step 1531/953240 - LR:0.0016 - train_loss: 3.416Step 1541/953240 - LR:0.0017 - train_loss: 3.328Step 1551/953240 - LR:0.0016 - train_loss: 3.348Step 1561/953240 - LR:0.0016 - train_loss: 3.307Step 1571/953240 - LR:0.0016 - train_loss: 3.333Step 1581/953240 - LR:0.0017 - train_loss: 3.326Step 1591/953240 - LR:0.0016 - train_loss: 3.337Step 1601/953240 - LR:0.0017 - train_loss: 3.271Step 1611/953240 - LR:0.0016 - train_loss: 3.406Step 1621/953240 - LR:0.0017 - train_loss: 3.304Step 1631/953240 - LR:0.0016 - train_loss: 3.332Step 1641/953240 - LR:0.0016 - train_loss: 3.265Step 1651/953240 - LR:0.0016 - train_loss: 3.295Step 1661/953240 - LR:0.0017 - train_loss: 3.213Step 1671/953240 - LR:0.0016 - train_loss: 3.346Step 1681/953240 - LR:0.0017 - train_loss: 3.246Step 1691/953240 - LR:0.0016 - train_loss: 3.406Step 1701/953240 - LR:0.0017 - train_loss: 3.255Step 1711/953240 - LR:0.0016 - train_loss: 3.301Step 1721/953240 - LR:0.0016 - train_loss: 3.226Step 1731/953240 - LR:0.0016 - train_loss: 3.295Step 1741/953240 - LR:0.0017 - train_loss: 3.234Step 1751/953240 - LR:0.0016 - train_loss: 3.325Step 1761/953240 - LR:0.0017 - train_loss: 3.229Step 1771/953240 - LR:0.0016 - train_loss: 3.222Step 1781/953240 - LR:0.0017 - train_loss: 3.192Step 1791/953240 - LR:0.0016 - train_loss: 3.216Step 1801/953240 - LR:0.0017 - train_loss: 3.169Step 1811/953240 - LR:0.0016 - train_loss: 3.218Step 1821/953240 - LR:0.0017 - train_loss: 3.187Step 1831/953240 - LR:0.0016 - train_loss: 3.245Step 1841/953240 - LR:0.0017 - train_loss: 3.208Step 1851/953240 - LR:0.0016 - train_loss: 3.325Step 1861/953240 - LR:0.0017 - train_loss: 3.214Step 1871/953240 - LR:0.0016 - train_loss: 3.216Step 1881/953240 - LR:0.0017 - train_loss: 3.123Step 1891/953240 - LR:0.0016 - train_loss: 3.213Step 1901/953240 - LR:0.0017 - train_loss: 3.134Step 1911/953240 - LR:0.0016 - train_loss: 3.133Step 1921/953240 - LR:0.0017 - train_loss: 3.133Step 1931/953240 - LR:0.0016 - train_loss: 3.153Step 1941/953240 - LR:0.0016 - train_loss: 3.134Step 1951/953240 - LR:0.0016 - train_loss: 3.173Step 1961/953240 - LR:0.0017 - train_loss: 3.141Step 1971/953240 - LR:0.0016 - train_loss: 3.160Step 1981/953240 - LR:0.0017 - train_loss: 3.158Step 1991/953240 - LR:0.0016 - train_loss: 3.133Step 2001/953240 - LR:0.0017 - train_loss: 3.109Step 2011/953240 - LR:0.0016 - train_loss: 3.121Step 2021/953240 - LR:0.0016 - train_loss: 3.079Step 2031/953240 - LR:0.0016 - train_loss: 3.140Step 2041/953240 - LR:0.0017 - train_loss: 3.105Step 2051/953240 - LR:0.0016 - train_loss: 3.193Step 2061/953240 - LR:0.0017 - train_loss: 3.071Step 2071/953240 - LR:0.0016 - train_loss: 3.141Step 2081/953240 - LR:0.0017 - train_loss: 3.078Step 2091/953240 - LR:0.0016 - train_loss: 3.142Step 2101/953240 - LR:0.0017 - train_loss: 3.070Step 2111/953240 - LR:0.0016 - train_loss: 3.057Step 2121/953240 - LR:0.0017 - train_loss: 3.044Step 2131/953240 - LR:0.0016 - train_loss: 3.058Step 2141/953240 - LR:0.0017 - train_loss: 3.006Step 2151/953240 - LR:0.0016 - train_loss: 3.086Step 2161/953240 - LR:0.0017 - train_loss: 3.001Step 2171/953240 - LR:0.0016 - train_loss: 3.094Step 2181/953240 - LR:0.0017 - train_loss: 3.055Step 2191/953240 - LR:0.0016 - train_loss: 3.112Step 2201/953240 - LR:0.0017 - train_loss: 3.020Step 2211/953240 - LR:0.0016 - train_loss: 3.060Step 2221/953240 - LR:0.0017 - train_loss: 3.006Step 2231/953240 - LR:0.0016 - train_loss: 3.075Step 2241/953240 - LR:0.0017 - train_loss: 3.002Step 2251/953240 - LR:0.0016 - train_loss: 3.040Step 2261/953240 - LR:0.0017 - train_loss: 2.986Step 2271/953240 - LR:0.0016 - train_loss: 3.032Step 2281/953240 - LR:0.0017 - train_loss: 2.991Step 2291/953240 - LR:0.0016 - train_loss: 3.051Step 2301/953240 - LR:0.0017 - train_loss: 2.979Step 2311/953240 - LR:0.0016 - train_loss: 3.021Step 2321/953240 - LR:0.0016 - train_loss: 2.976Step 2331/953240 - LR:0.0016 - train_loss: 3.014Step 2341/953240 - LR:0.0017 - train_loss: 2.962Step 2351/953240 - LR:0.0016 - train_loss: 3.030Step 2361/953240 - LR:0.0017 - train_loss: 2.975Step 2371/953240 - LR:0.0016 - train_loss: 3.014Step 2381/953240 - LR:0.0017 - train_loss: 2.919Step 2391/953240 - LR:0.0016 - train_loss: 3.035Step 2401/953240 - LR:0.0017 - train_loss: 2.943Step 2411/953240 - LR:0.0016 - train_loss: 3.008Step 2421/953240 - LR:0.0017 - train_loss: 2.907Step 2431/953240 - LR:0.0016 - train_loss: 2.986Step 2441/953240 - LR:0.0017 - train_loss: 2.921Step 2451/953240 - LR:0.0016 - train_loss: 2.973Step 2461/953240 - LR:0.0017 - train_loss: 2.917Step 2471/953240 - LR:0.0016 - train_loss: 2.974Step 2481/953240 - LR:0.0017 - train_loss: 2.921Step 2491/953240 - LR:0.0016 - train_loss: 2.956Step 2501/953240 - LR:0.0017 - train_loss: 2.882Step 2511/953240 - LR:0.0016 - train_loss: 2.950Step 2521/953240 - LR:0.0017 - train_loss: 2.917Step 2531/953240 - LR:0.0016 - train_loss: 2.973Step 2541/953240 - LR:0.0017 - train_loss: 2.896Step 2551/953240 - LR:0.0016 - train_loss: 2.946Step 2561/953240 - LR:0.0017 - train_loss: 2.889Step 2571/953240 - LR:0.0016 - train_loss: 2.916Step 2581/953240 - LR:0.0017 - train_loss: 2.863Step 2591/953240 - LR:0.0016 - train_loss: 2.941Step 2601/953240 - LR:0.0017 - train_loss: 2.861Step 2611/953240 - LR:0.0016 - train_loss: 2.905Step 2621/953240 - LR:0.0017 - train_loss: 2.851Step 2631/953240 - LR:0.0016 - train_loss: 2.933Step 2641/953240 - LR:0.0017 - train_loss: 2.869Step 2651/953240 - LR:0.0016 - train_loss: 2.922Step 2661/953240 - LR:0.0017 - train_loss: 2.821Step 2671/953240 - LR:0.0016 - train_loss: 2.955Step 2681/953240 - LR:0.0017 - train_loss: 2.854Step 2691/953240 - LR:0.0016 - train_loss: 2.968Step 2701/953240 - LR:0.0017 - train_loss: 2.832Step 2711/953240 - LR:0.0016 - train_loss: 2.876Step 2721/953240 - LR:0.0017 - train_loss: 2.813Step 2731/953240 - LR:0.0016 - train_loss: 2.852Step 2741/953240 - LR:0.0017 - train_loss: 2.809Step 2751/953240 - LR:0.0016 - train_loss: 2.870Step 2761/953240 - LR:0.0017 - train_loss: 2.817Step 2771/953240 - LR:0.0016 - train_loss: 2.858Step 2781/953240 - LR:0.0017 - train_loss: 2.821Step 2791/953240 - LR:0.0016 - train_loss: 2.819Step 2801/953240 - LR:0.0017 - train_loss: 2.804Step 2811/953240 - LR:0.0016 - train_loss: 2.859Step 2821/953240 - LR:0.0016 - train_loss: 2.773Step 2831/953240 - LR:0.0016 - train_loss: 2.838Step 2841/953240 - LR:0.0017 - train_loss: 2.788Step 2851/953240 - LR:0.0016 - train_loss: 2.823Step 2861/953240 - LR:0.0017 - train_loss: 2.800Step 2871/953240 - LR:0.0016 - train_loss: 2.825Step 2881/953240 - LR:0.0017 - train_loss: 2.769Step 2891/953240 - LR:0.0016 - train_loss: 2.789Step 2901/953240 - LR:0.0017 - train_loss: 2.746Step 2911/953240 - LR:0.0016 - train_loss: 2.812Step 2921/953240 - LR:0.0017 - train_loss: 2.778Step 2931/953240 - LR:0.0016 - train_loss: 2.775Step 2941/953240 - LR:0.0017 - train_loss: 2.759Step 2951/953240 - LR:0.0016 - train_loss: 2.809Step 2961/953240 - LR:0.0017 - train_loss: 2.779Step 2971/953240 - LR:0.0016 - train_loss: 2.803Step 2981/953240 - LR:0.0016 - train_loss: 2.747Step 2991/953240 - LR:0.0016 - train_loss: 2.829Step 3001/953240 - LR:0.0017 - train_loss: 2.734Step 3011/953240 - LR:0.0016 - train_loss: 2.748Step 3021/953240 - LR:0.0017 - train_loss: 2.721Step 3031/953240 - LR:0.0016 - train_loss: 2.782Step 3041/953240 - LR:0.0017 - train_loss: 2.726Step 3051/953240 - LR:0.0016 - train_loss: 2.787Step 3061/953240 - LR:0.0017 - train_loss: 2.733Step 3071/953240 - LR:0.0016 - train_loss: 2.789Step 3081/953240 - LR:0.0017 - train_loss: 2.700Step 3091/953240 - LR:0.0016 - train_loss: 2.782Step 3101/953240 - LR:0.0017 - train_loss: 2.730Step 3111/953240 - LR:0.0016 - train_loss: 2.785Step 3121/953240 - LR:0.0017 - train_loss: 2.684Step 3131/953240 - LR:0.0016 - train_loss: 2.747Step 3141/953240 - LR:0.0017 - train_loss: 2.676Step 3151/953240 - LR:0.0016 - train_loss: 2.717Step 3161/953240 - LR:0.0017 - train_loss: 2.684Step 3171/953240 - LR:0.0016 - train_loss: 2.730Step 3181/953240 - LR:0.0017 - train_loss: 2.685Step 3191/953240 - LR:0.0016 - train_loss: 2.712Step 3201/953240 - LR:0.0016 - train_loss: 2.668Step 3211/953240 - LR:0.0016 - train_loss: 2.690Step 3221/953240 - LR:0.0017 - train_loss: 2.646Step 3231/953240 - LR:0.0016 - train_loss: 2.667Step 3241/953240 - LR:0.0017 - train_loss: 2.629Step 3251/953240 - LR:0.0016 - train_loss: 2.690Step 3261/953240 - LR:0.0017 - train_loss: 2.659Step 3271/953240 - LR:0.0016 - train_loss: 2.724Step 3281/953240 - LR:0.0017 - train_loss: 2.618Step 3291/953240 - LR:0.0016 - train_loss: 2.673Step 3301/953240 - LR:0.0017 - train_loss: 2.644Step 3311/953240 - LR:0.0016 - train_loss: 2.698Step 3321/953240 - LR:0.0017 - train_loss: 2.640Step 3331/953240 - LR:0.0016 - train_loss: 2.671Step 3341/953240 - LR:0.0017 - train_loss: 2.630Step 3351/953240 - LR:0.0016 - train_loss: 2.677Step 3361/953240 - LR:0.0016 - train_loss: 2.637Step 3371/953240 - LR:0.0016 - train_loss: 2.652Step 3381/953240 - LR:0.0017 - train_loss: 2.594Step 3391/953240 - LR:0.0016 - train_loss: 2.682Step 3401/953240 - LR:0.0017 - train_loss: 2.567Step 3411/953240 - LR:0.0016 - train_loss: 2.651Step 3421/953240 - LR:0.0017 - train_loss: 2.588Step 3431/953240 - LR:0.0016 - train_loss: 2.606Step 3441/953240 - LR:0.0017 - train_loss: 2.626Step 3451/953240 - LR:0.0016 - train_loss: 2.647Step 3461/953240 - LR:0.0017 - train_loss: 2.614Step 3471/953240 - LR:0.0016 - train_loss: 2.649Step 3481/953240 - LR:0.0017 - train_loss: 2.545Step 3491/953240 - LR:0.0016 - train_loss: 2.632Step 3501/953240 - LR:0.0017 - train_loss: 2.593Step 3511/953240 - LR:0.0016 - train_loss: 2.599Step 3521/953240 - LR:0.0017 - train_loss: 2.600Step 3531/953240 - LR:0.0016 - train_loss: 2.570Step 3541/953240 - LR:0.0017 - train_loss: 2.548Step 3551/953240 - LR:0.0016 - train_loss: 2.632Step 3561/953240 - LR:0.0017 - train_loss: 2.553Step 3571/953240 - LR:0.0016 - train_loss: 2.642Step 3581/953240 - LR:0.0016 - train_loss: 2.527Step 3591/953240 - LR:0.0016 - train_loss: 2.594Step 3601/953240 - LR:0.0017 - train_loss: 2.557Step 3611/953240 - LR:0.0016 - train_loss: 2.606Step 3621/953240 - LR:0.0017 - train_loss: 2.560Step 3631/953240 - LR:0.0016 - train_loss: 2.622Step 3641/953240 - LR:0.0017 - train_loss: 2.533Step 3651/953240 - LR:0.0016 - train_loss: 2.614Step 3661/953240 - LR:0.0017 - train_loss: 2.528Step 3671/953240 - LR:0.0016 - train_loss: 2.602Step 3681/953240 - LR:0.0017 - train_loss: 2.541Step 3691/953240 - LR:0.0016 - train_loss: 2.540Step 3701/953240 - LR:0.0017 - train_loss: 2.510Step 3711/953240 - LR:0.0016 - train_loss: 2.525Step 3721/953240 - LR:0.0017 - train_loss: 2.520Step 3731/953240 - LR:0.0016 - train_loss: 2.531Step 3741/953240 - LR:0.0017 - train_loss: 2.515Step 3751/953240 - LR:0.0016 - train_loss: 2.598Step 3761/953240 - LR:0.0017 - train_loss: 2.480Step 3771/953240 - LR:0.0016 - train_loss: 2.485Step 3781/953240 - LR:0.0017 - train_loss: 2.505Step 3791/953240 - LR:0.0016 - train_loss: 2.549Step 3801/953240 - LR:0.0017 - train_loss: 2.483Step 3811/953240 - LR:0.0016 - train_loss: 2.556Step 3821/953240 - LR:0.0017 - train_loss: 2.517Step 3831/953240 - LR:0.0016 - train_loss: 2.565Step 3841/953240 - LR:0.0017 - train_loss: 2.504Step 3851/953240 - LR:0.0016 - train_loss: 2.501Step 3861/953240 - LR:0.0017 - train_loss: 2.469Step 3871/953240 - LR:0.0016 - train_loss: 2.497Step 3881/953240 - LR:0.0017 - train_loss: 2.452Step 3891/953240 - LR:0.0016 - train_loss: 2.511Step 3901/953240 - LR:0.0017 - train_loss: 2.434Step 3911/953240 - LR:0.0016 - train_loss: 2.499Step 3921/953240 - LR:0.0017 - train_loss: 2.438Step 3931/953240 - LR:0.0016 - train_loss: 2.523Step 3941/953240 - LR:0.0017 - train_loss: 2.443Step 3951/953240 - LR:0.0016 - train_loss: 2.514Step 3961/953240 - LR:0.0016 - train_loss: 2.445Step 3971/953240 - LR:0.0016 - train_loss: 2.492Step 3981/953240 - LR:0.0017 - train_loss: 2.442Step 3991/953240 - LR:0.0016 - train_loss: 2.474Step 4001/953240 - LR:0.0017 - train_loss: 2.439Step 4011/953240 - LR:0.0016 - train_loss: 2.492Step 4021/953240 - LR:0.0017 - train_loss: 2.429Step 4031/953240 - LR:0.0016 - train_loss: 2.484Step 4041/953240 - LR:0.0017 - train_loss: 2.432Step 4051/953240 - LR:0.0016 - train_loss: 2.453Step 4061/953240 - LR:0.0017 - train_loss: 2.418Step 4071/953240 - LR:0.0016 - train_loss: 2.453Step 4081/953240 - LR:0.0017 - train_loss: 2.465Step 4091/953240 - LR:0.0016 - train_loss: 2.467Step 4101/953240 - LR:0.0017 - train_loss: 2.413Step 4111/953240 - LR:0.0016 - train_loss: 2.424Step 4121/953240 - LR:0.0017 - train_loss: 2.429Step 4131/953240 - LR:0.0016 - train_loss: 2.485Step 4141/953240 - LR:0.0017 - train_loss: 2.408Step 4151/953240 - LR:0.0016 - train_loss: 2.440Step 4161/953240 - LR:0.0017 - train_loss: 2.387Step 4171/953240 - LR:0.0016 - train_loss: 2.436Step 4181/953240 - LR:0.0017 - train_loss: 2.337Step 4191/953240 - LR:0.0016 - train_loss: 2.404Step 4201/953240 - LR:0.0017 - train_loss: 2.392Step 4211/953240 - LR:0.0016 - train_loss: 2.420Step 4221/953240 - LR:0.0017 - train_loss: 2.402Step 4231/953240 - LR:0.0016 - train_loss: 2.440Step 4241/953240 - LR:0.0017 - train_loss: 2.392Step 4251/953240 - LR:0.0016 - train_loss: 2.429Step 4261/953240 - LR:0.0017 - train_loss: 2.391Step 4271/953240 - LR:0.0016 - train_loss: 2.429Step 4281/953240 - LR:0.0017 - train_loss: 2.366Step 4291/953240 - LR:0.0016 - train_loss: 2.434Step 4301/953240 - LR:0.0017 - train_loss: 2.398Step 4311/953240 - LR:0.0016 - train_loss: 2.359Step 4321/953240 - LR:0.0017 - train_loss: 2.345Step 4331/953240 - LR:0.0016 - train_loss: 2.415Step 4341/953240 - LR:0.0017 - train_loss: 2.383Step 4351/953240 - LR:0.0016 - train_loss: 2.400Step 4361/953240 - LR:0.0017 - train_loss: 2.387Step 4371/953240 - LR:0.0016 - train_loss: 2.406Step 4381/953240 - LR:0.0017 - train_loss: 2.355Step 4391/953240 - LR:0.0016 - train_loss: 2.374Step 4401/953240 - LR:0.0017 - train_loss: 2.358Step 4411/953240 - LR:0.0016 - train_loss: 2.386Step 4421/953240 - LR:0.0017 - train_loss: 2.315Step 4431/953240 - LR:0.0016 - train_loss: 2.337Step 4441/953240 - LR:0.0017 - train_loss: 2.336Step 4451/953240 - LR:0.0016 - train_loss: 2.359Step 4461/953240 - LR:0.0017 - train_loss: 2.336Step 4471/953240 - LR:0.0016 - train_loss: 2.382Step 4481/953240 - LR:0.0017 - train_loss: 2.371Step 4491/953240 - LR:0.0016 - train_loss: 2.385Step 4501/953240 - LR:0.0017 - train_loss: 2.333Step 4511/953240 - LR:0.0016 - train_loss: 2.348Step 4521/953240 - LR:0.0017 - train_loss: 2.352Step 4531/953240 - LR:0.0016 - train_loss: 2.373Step 4541/953240 - LR:0.0017 - train_loss: 2.320Step 4551/953240 - LR:0.0016 - train_loss: 2.340Step 4561/953240 - LR:0.0017 - train_loss: 2.310Step 4571/953240 - LR:0.0016 - train_loss: 2.360Step 4581/953240 - LR:0.0017 - train_loss: 2.339Step 4591/953240 - LR:0.0016 - train_loss: 2.361Step 4601/953240 - LR:0.0017 - train_loss: 2.300Step 4611/953240 - LR:0.0016 - train_loss: 2.350Step 4621/953240 - LR:0.0017 - train_loss: 2.334Step 4631/953240 - LR:0.0016 - train_loss: 2.347Step 4641/953240 - LR:0.0017 - train_loss: 2.289Step 4651/953240 - LR:0.0016 - train_loss: 2.321Step 4661/953240 - LR:0.0017 - train_loss: 2.285Step 4671/953240 - LR:0.0016 - train_loss: 2.340Step 4681/953240 - LR:0.0017 - train_loss: 2.297Step 4691/953240 - LR:0.0016 - train_loss: 2.327Step 4701/953240 - LR:0.0017 - train_loss: 2.253Step 4711/953240 - LR:0.0016 - train_loss: 2.350Step 4721/953240 - LR:0.0017 - train_loss: 2.313Step 4731/953240 - LR:0.0016 - train_loss: 2.309Step 4741/953240 - LR:0.0017 - train_loss: 2.285Step 4751/953240 - LR:0.0016 - train_loss: 2.330Step 4761/953240 - LR:0.0017 - train_loss: 2.304Step 4771/953240 - LR:0.0016 - train_loss: 2.292Step 4781/953240 - LR:0.0017 - train_loss: 2.286Step 4791/953240 - LR:0.0016 - train_loss: 2.336Step 4801/953240 - LR:0.0017 - train_loss: 2.273Step 4811/953240 - LR:0.0016 - train_loss: 2.305Step 4821/953240 - LR:0.0017 - train_loss: 2.251Step 4831/953240 - LR:0.0016 - train_loss: 2.277Step 4841/953240 - LR:0.0017 - train_loss: 2.262Step 4851/953240 - LR:0.0016 - train_loss: 2.312Step 4861/953240 - LR:0.0017 - train_loss: 2.268Step 4871/953240 - LR:0.0016 - train_loss: 2.294Step 4881/953240 - LR:0.0017 - train_loss: 2.275Step 4891/953240 - LR:0.0016 - train_loss: 2.310Step 4901/953240 - LR:0.0017 - train_loss: 2.238Step 4911/953240 - LR:0.0016 - train_loss: 2.248Step 4921/953240 - LR:0.0017 - train_loss: 2.241Step 4931/953240 - LR:0.0016 - train_loss: 2.244Step 4941/953240 - LR:0.0017 - train_loss: 2.250Step 4951/953240 - LR:0.0016 - train_loss: 2.246Step 4961/953240 - LR:0.0017 - train_loss: 2.234Step 4971/953240 - LR:0.0016 - train_loss: 2.234Step 4981/953240 - LR:0.0017 - train_loss: 2.220Step 4991/953240 - LR:0.0016 - train_loss: 2.247Step 5001/953240 - LR:0.0017 - train_loss: 2.232
Epoch 2/2:
Step 1/953240 - LR:0.0003 - train_loss: 2.252Step 11/953240 - LR:0.0030 - train_loss: 2.245Step 21/953240 - LR:0.0003 - train_loss: 2.286Step 31/953240 - LR:0.0030 - train_loss: 2.248Step 41/953240 - LR:0.0003 - train_loss: 2.262Step 51/953240 - LR:0.0030 - train_loss: 2.279Step 61/953240 - LR:0.0003 - train_loss: 2.249Step 71/953240 - LR:0.0030 - train_loss: 2.278Step 81/953240 - LR:0.0003 - train_loss: 2.266Step 91/953240 - LR:0.0030 - train_loss: 2.252Step 101/953240 - LR:0.0003 - train_loss: 2.266Step 111/953240 - LR:0.0030 - train_loss: 2.224Step 121/953240 - LR:0.0003 - train_loss: 2.237Step 131/953240 - LR:0.0030 - train_loss: 2.243Step 141/953240 - LR:0.0003 - train_loss: 2.234Step 151/953240 - LR:0.0030 - train_loss: 2.255Step 161/953240 - LR:0.0003 - train_loss: 2.258Step 171/953240 - LR:0.0030 - train_loss: 2.281Step 181/953240 - LR:0.0003 - train_loss: 2.273Step 191/953240 - LR:0.0030 - train_loss: 2.278Step 201/953240 - LR:0.0003 - train_loss: 2.260Step 211/953240 - LR:0.0030 - train_loss: 2.238Step 221/953240 - LR:0.0003 - train_loss: 2.233Step 231/953240 - LR:0.0030 - train_loss: 2.214Step 241/953240 - LR:0.0003 - train_loss: 2.253Step 251/953240 - LR:0.0030 - train_loss: 2.236Step 261/953240 - LR:0.0003 - train_loss: 2.258Step 271/953240 - LR:0.0030 - train_loss: 2.271Step 281/953240 - LR:0.0003 - train_loss: 2.214Step 291/953240 - LR:0.0030 - train_loss: 2.243Step 301/953240 - LR:0.0003 - train_loss: 2.249Step 311/953240 - LR:0.0030 - train_loss: 2.256Step 321/953240 - LR:0.0003 - train_loss: 2.207Step 331/953240 - LR:0.0030 - train_loss: 2.219Step 341/953240 - LR:0.0003 - train_loss: 2.205Step 351/953240 - LR:0.0030 - train_loss: 2.240Step 361/953240 - LR:0.0003 - train_loss: 2.184Step 371/953240 - LR:0.0030 - train_loss: 2.233Step 381/953240 - LR:0.0003 - train_loss: 2.233Step 391/953240 - LR:0.0030 - train_loss: 2.169Step 401/953240 - LR:0.0003 - train_loss: 2.201Step 411/953240 - LR:0.0030 - train_loss: 2.271Step 421/953240 - LR:0.0003 - train_loss: 2.202Step 431/953240 - LR:0.0030 - train_loss: 2.204Step 441/953240 - LR:0.0003 - train_loss: 2.196Step 451/953240 - LR:0.0030 - train_loss: 2.211Step 461/953240 - LR:0.0003 - train_loss: 2.224Step 471/953240 - LR:0.0030 - train_loss: 2.217Step 481/953240 - LR:0.0003 - train_loss: 2.181Step 491/953240 - LR:0.0030 - train_loss: 2.200Step 501/953240 - LR:0.0003 - train_loss: 2.222Step 511/953240 - LR:0.0030 - train_loss: 2.195Step 521/953240 - LR:0.0003 - train_loss: 2.224Step 531/953240 - LR:0.0030 - train_loss: 2.193Step 541/953240 - LR:0.0003 - train_loss: 2.177Step 551/953240 - LR:0.0030 - train_loss: 2.206Step 561/953240 - LR:0.0003 - train_loss: 2.188Step 571/953240 - LR:0.0030 - train_loss: 2.206Step 581/953240 - LR:0.0003 - train_loss: 2.192Step 591/953240 - LR:0.0030 - train_loss: 2.201Step 601/953240 - LR:0.0003 - train_loss: 2.170Step 611/953240 - LR:0.0030 - train_loss: 2.145Step 621/953240 - LR:0.0003 - train_loss: 2.186Step 631/953240 - LR:0.0030 - train_loss: 2.187Step 641/953240 - LR:0.0003 - train_loss: 2.198Step 651/953240 - LR:0.0030 - train_loss: 2.199Step 661/953240 - LR:0.0003 - train_loss: 2.167Step 671/953240 - LR:0.0030 - train_loss: 2.222Step 681/953240 - LR:0.0003 - train_loss: 2.163Step 691/953240 - LR:0.0030 - train_loss: 2.204Step 701/953240 - LR:0.0003 - train_loss: 2.135Step 711/953240 - LR:0.0030 - train_loss: 2.103Step 721/953240 - LR:0.0003 - train_loss: 2.144Step 731/953240 - LR:0.0030 - train_loss: 2.165Step 741/953240 - LR:0.0003 - train_loss: 2.189Step 751/953240 - LR:0.0030 - train_loss: 2.168Step 761/953240 - LR:0.0003 - train_loss: 2.129Step 771/953240 - LR:0.0030 - train_loss: 2.188Step 781/953240 - LR:0.0003 - train_loss: 2.140Step 791/953240 - LR:0.0030 - train_loss: 2.172Step 801/953240 - LR:0.0003 - train_loss: 2.154Step 811/953240 - LR:0.0030 - train_loss: 2.137Step 821/953240 - LR:0.0003 - train_loss: 2.128Step 831/953240 - LR:0.0030 - train_loss: 2.150Step 841/953240 - LR:0.0003 - train_loss: 2.151Step 851/953240 - LR:0.0030 - train_loss: 2.158Step 861/953240 - LR:0.0003 - train_loss: 2.099Step 871/953240 - LR:0.0030 - train_loss: 2.144Step 881/953240 - LR:0.0003 - train_loss: 2.140Step 891/953240 - LR:0.0030 - train_loss: 2.166Step 901/953240 - LR:0.0003 - train_loss: 2.129Step 911/953240 - LR:0.0030 - train_loss: 2.148Step 921/953240 - LR:0.0003 - train_loss: 2.132Step 931/953240 - LR:0.0030 - train_loss: 2.187Step 941/953240 - LR:0.0003 - train_loss: 2.116Step 951/953240 - LR:0.0030 - train_loss: 2.143Step 961/953240 - LR:0.0003 - train_loss: 2.132Step 971/953240 - LR:0.0030 - train_loss: 2.158Step 981/953240 - LR:0.0003 - train_loss: 2.132Step 991/953240 - LR:0.0030 - train_loss: 2.170Step 1001/953240 - LR:0.0003 - train_loss: 2.190Step 1011/953240 - LR:0.0030 - train_loss: 2.119Step 1021/953240 - LR:0.0003 - train_loss: 2.137Step 1031/953240 - LR:0.0030 - train_loss: 2.148Step 1041/953240 - LR:0.0003 - train_loss: 2.133Step 1051/953240 - LR:0.0030 - train_loss: 2.108Step 1061/953240 - LR:0.0003 - train_loss: 2.135Step 1071/953240 - LR:0.0030 - train_loss: 2.153Step 1081/953240 - LR:0.0003 - train_loss: 2.169Step 1091/953240 - LR:0.0030 - train_loss: 2.131Step 1101/953240 - LR:0.0003 - train_loss: 2.143Step 1111/953240 - LR:0.0030 - train_loss: 2.145Step 1121/953240 - LR:0.0003 - train_loss: 2.101Step 1131/953240 - LR:0.0030 - train_loss: 2.156Step 1141/953240 - LR:0.0003 - train_loss: 2.117Step 1151/953240 - LR:0.0030 - train_loss: 2.140Step 1161/953240 - LR:0.0003 - train_loss: 2.104Step 1171/953240 - LR:0.0030 - train_loss: 2.113Step 1181/953240 - LR:0.0003 - train_loss: 2.115Step 1191/953240 - LR:0.0030 - train_loss: 2.134Step 1201/953240 - LR:0.0003 - train_loss: 2.128Step 1211/953240 - LR:0.0030 - train_loss: 2.136Step 1221/953240 - LR:0.0003 - train_loss: 2.089Step 1231/953240 - LR:0.0030 - train_loss: 2.106Step 1241/953240 - LR:0.0003 - train_loss: 2.114Step 1251/953240 - LR:0.0030 - train_loss: 2.123Step 1261/953240 - LR:0.0003 - train_loss: 2.123Step 1271/953240 - LR:0.0030 - train_loss: 2.125Step 1281/953240 - LR:0.0003 - train_loss: 2.117Step 1291/953240 - LR:0.0030 - train_loss: 2.138Step 1301/953240 - LR:0.0003 - train_loss: 2.112Step 1311/953240 - LR:0.0030 - train_loss: 2.099Step 1321/953240 - LR:0.0003 - train_loss: 2.095Step 1331/953240 - LR:0.0030 - train_loss: 2.118Step 1341/953240 - LR:0.0003 - train_loss: 2.075Step 1351/953240 - LR:0.0030 - train_loss: 2.143Step 1361/953240 - LR:0.0003 - train_loss: 2.094Step 1371/953240 - LR:0.0030 - train_loss: 2.100Step 1381/953240 - LR:0.0003 - train_loss: 2.109Step 1391/953240 - LR:0.0030 - train_loss: 2.088Step 1401/953240 - LR:0.0003 - train_loss: 2.115Step 1411/953240 - LR:0.0030 - train_loss: 2.142Step 1421/953240 - LR:0.0003 - train_loss: 2.053Step 1431/953240 - LR:0.0030 - train_loss: 2.086Step 1441/953240 - LR:0.0003 - train_loss: 2.140Step 1451/953240 - LR:0.0030 - train_loss: 2.084Step 1461/953240 - LR:0.0003 - train_loss: 2.104Step 1471/953240 - LR:0.0030 - train_loss: 2.091Step 1481/953240 - LR:0.0003 - train_loss: 2.091Step 1491/953240 - LR:0.0030 - train_loss: 2.066Step 1501/953240 - LR:0.0003 - train_loss: 2.097Step 1511/953240 - LR:0.0030 - train_loss: 2.061Step 1521/953240 - LR:0.0003 - train_loss: 2.067Step 1531/953240 - LR:0.0030 - train_loss: 2.056Step 1541/953240 - LR:0.0003 - train_loss: 2.071Step 1551/953240 - LR:0.0030 - train_loss: 2.095Step 1561/953240 - LR:0.0003 - train_loss: 2.066Step 1571/953240 - LR:0.0030 - train_loss: 2.090Step 1581/953240 - LR:0.0003 - train_loss: 2.109Step 1591/953240 - LR:0.0030 - train_loss: 2.069Step 1601/953240 - LR:0.0003 - train_loss: 2.080Step 1611/953240 - LR:0.0030 - train_loss: 2.090Step 1621/953240 - LR:0.0003 - train_loss: 2.117Step 1631/953240 - LR:0.0030 - train_loss: 2.101Step 1641/953240 - LR:0.0003 - train_loss: 2.068Step 1651/953240 - LR:0.0030 - train_loss: 2.091Step 1661/953240 - LR:0.0003 - train_loss: 2.046Step 1671/953240 - LR:0.0030 - train_loss: 2.078Step 1681/953240 - LR:0.0003 - train_loss: 2.089Step 1691/953240 - LR:0.0030 - train_loss: 2.106Step 1701/953240 - LR:0.0003 - train_loss: 2.059Step 1711/953240 - LR:0.0030 - train_loss: 2.080Step 1721/953240 - LR:0.0003 - train_loss: 2.067Step 1731/953240 - LR:0.0030 - train_loss: 2.073Step 1741/953240 - LR:0.0003 - train_loss: 2.072Step 1751/953240 - LR:0.0030 - train_loss: 2.077Step 1761/953240 - LR:0.0003 - train_loss: 2.077Step 1771/953240 - LR:0.0030 - train_loss: 2.086Step 1781/953240 - LR:0.0003 - train_loss: 2.040Step 1791/953240 - LR:0.0030 - train_loss: 2.078Step 1801/953240 - LR:0.0003 - train_loss: 2.081Step 1811/953240 - LR:0.0030 - train_loss: 2.031Step 1821/953240 - LR:0.0003 - train_loss: 2.050Step 1831/953240 - LR:0.0030 - train_loss: 2.077Step 1841/953240 - LR:0.0003 - train_loss: 2.060Step 1851/953240 - LR:0.0030 - train_loss: 2.068Step 1861/953240 - LR:0.0003 - train_loss: 2.070Step 1871/953240 - LR:0.0030 - train_loss: 2.067Step 1881/953240 - LR:0.0003 - train_loss: 2.059Step 1891/953240 - LR:0.0030 - train_loss: 2.053Step 1901/953240 - LR:0.0003 - train_loss: 2.051Step 1911/953240 - LR:0.0030 - train_loss: 2.066Step 1921/953240 - LR:0.0003 - train_loss: 2.068Step 1931/953240 - LR:0.0030 - train_loss: 2.047Step 1941/953240 - LR:0.0003 - train_loss: 2.018Step 1951/953240 - LR:0.0030 - train_loss: 2.051Step 1961/953240 - LR:0.0003 - train_loss: 2.022Step 1971/953240 - LR:0.0030 - train_loss: 2.084Step 1981/953240 - LR:0.0003 - train_loss: 2.069Step 1991/953240 - LR:0.0030 - train_loss: 2.045Step 2001/953240 - LR:0.0003 - train_loss: 2.050Step 2011/953240 - LR:0.0030 - train_loss: 2.040Step 2021/953240 - LR:0.0003 - train_loss: 2.066Step 2031/953240 - LR:0.0030 - train_loss: 2.061Step 2041/953240 - LR:0.0003 - train_loss: 2.033Step 2051/953240 - LR:0.0030 - train_loss: 2.072Step 2061/953240 - LR:0.0003 - train_loss: 2.042Step 2071/953240 - LR:0.0030 - train_loss: 2.058Step 2081/953240 - LR:0.0003 - train_loss: 2.063Step 2091/953240 - LR:0.0030 - train_loss: 2.063Step 2101/953240 - LR:0.0003 - train_loss: 2.059Step 2111/953240 - LR:0.0030 - train_loss: 2.009Step 2121/953240 - LR:0.0003 - train_loss: 2.048Step 2131/953240 - LR:0.0030 - train_loss: 2.048Step 2141/953240 - LR:0.0003 - train_loss: 2.050Step 2151/953240 - LR:0.0030 - train_loss: 2.035Step 2161/953240 - LR:0.0003 - train_loss: 2.047Step 2171/953240 - LR:0.0030 - train_loss: 2.059Step 2181/953240 - LR:0.0003 - train_loss: 2.079Step 2191/953240 - LR:0.0030 - train_loss: 2.091Step 2201/953240 - LR:0.0003 - train_loss: 2.068Step 2211/953240 - LR:0.0030 - train_loss: 2.052Step 2221/953240 - LR:0.0003 - train_loss: 2.043Step 2231/953240 - LR:0.0030 - train_loss: 2.025Step 2241/953240 - LR:0.0003 - train_loss: 2.060Step 2251/953240 - LR:0.0030 - train_loss: 2.022Step 2261/953240 - LR:0.0003 - train_loss: 2.026Step 2271/953240 - LR:0.0030 - train_loss: 2.045Step 2281/953240 - LR:0.0003 - train_loss: 2.045Step 2291/953240 - LR:0.0030 - train_loss: 2.027Step 2301/953240 - LR:0.0003 - train_loss: 2.029Step 2311/953240 - LR:0.0030 - train_loss: 2.048Step 2321/953240 - LR:0.0003 - train_loss: 2.066Step 2331/953240 - LR:0.0030 - train_loss: 2.042Step 2341/953240 - LR:0.0003 - train_loss: 2.048Step 2351/953240 - LR:0.0030 - train_loss: 2.015Step 2361/953240 - LR:0.0003 - train_loss: 2.019Step 2371/953240 - LR:0.0030 - train_loss: 2.037Step 2381/953240 - LR:0.0003 - train_loss: 2.040Step 2391/953240 - LR:0.0030 - train_loss: 2.022Step 2401/953240 - LR:0.0003 - train_loss: 2.051Step 2411/953240 - LR:0.0030 - train_loss: 2.025Step 2421/953240 - LR:0.0003 - train_loss: 2.041Step 2431/953240 - LR:0.0030 - train_loss: 2.028Step 2441/953240 - LR:0.0003 - train_loss: 1.998Step 2451/953240 - LR:0.0030 - train_loss: 2.020Step 2461/953240 - LR:0.0003 - train_loss: 2.047Step 2471/953240 - LR:0.0030 - train_loss: 1.986Step 2481/953240 - LR:0.0003 - train_loss: 2.027Step 2491/953240 - LR:0.0030 - train_loss: 2.046Step 2501/953240 - LR:0.0003 - train_loss: 2.007Step 2511/953240 - LR:0.0030 - train_loss: 2.041Step 2521/953240 - LR:0.0003 - train_loss: 2.041Step 2531/953240 - LR:0.0030 - train_loss: 2.048Step 2541/953240 - LR:0.0003 - train_loss: 2.036Step 2551/953240 - LR:0.0030 - train_loss: 2.002Step 2561/953240 - LR:0.0003 - train_loss: 2.056Step 2571/953240 - LR:0.0030 - train_loss: 1.985Step 2581/953240 - LR:0.0003 - train_loss: 1.986Step 2591/953240 - LR:0.0030 - train_loss: 2.027Step 2601/953240 - LR:0.0003 - train_loss: 2.009Step 2611/953240 - LR:0.0030 - train_loss: 2.026Step 2621/953240 - LR:0.0003 - train_loss: 2.028Step 2631/953240 - LR:0.0030 - train_loss: 2.045Step 2641/953240 - LR:0.0003 - train_loss: 2.005Step 2651/953240 - LR:0.0030 - train_loss: 1.974Step 2661/953240 - LR:0.0003 - train_loss: 2.002Step 2671/953240 - LR:0.0030 - train_loss: 2.035Step 2681/953240 - LR:0.0003 - train_loss: 2.029Step 2691/953240 - LR:0.0030 - train_loss: 2.050Step 2701/953240 - LR:0.0003 - train_loss: 2.010Step 2711/953240 - LR:0.0030 - train_loss: 2.047Step 2721/953240 - LR:0.0003 - train_loss: 2.025Step 2731/953240 - LR:0.0030 - train_loss: 2.041Step 2741/953240 - LR:0.0003 - train_loss: 2.032Step 2751/953240 - LR:0.0030 - train_loss: 2.004Step 2761/953240 - LR:0.0003 - train_loss: 1.994Step 2771/953240 - LR:0.0030 - train_loss: 2.004Step 2781/953240 - LR:0.0003 - train_loss: 2.019Step 2791/953240 - LR:0.0030 - train_loss: 2.036Step 2801/953240 - LR:0.0003 - train_loss: 2.044Step 2811/953240 - LR:0.0030 - train_loss: 2.059Step 2821/953240 - LR:0.0003 - train_loss: 2.017Step 2831/953240 - LR:0.0030 - train_loss: 2.009Step 2841/953240 - LR:0.0003 - train_loss: 2.064Step 2851/953240 - LR:0.0030 - train_loss: 2.000Step 2861/953240 - LR:0.0003 - train_loss: 2.019Step 2871/953240 - LR:0.0030 - train_loss: 2.042Step 2881/953240 - LR:0.0003 - train_loss: 2.004Step 2891/953240 - LR:0.0030 - train_loss: 1.969Step 2901/953240 - LR:0.0003 - train_loss: 2.027Step 2911/953240 - LR:0.0030 - train_loss: 1.995Step 2921/953240 - LR:0.0003 - train_loss: 1.998Step 2931/953240 - LR:0.0030 - train_loss: 2.010Step 2941/953240 - LR:0.0003 - train_loss: 1.997Step 2951/953240 - LR:0.0030 - train_loss: 1.983Step 2961/953240 - LR:0.0003 - train_loss: 1.997Step 2971/953240 - LR:0.0030 - train_loss: 2.000Step 2981/953240 - LR:0.0003 - train_loss: 2.011Step 2991/953240 - LR:0.0030 - train_loss: 2.008Step 3001/953240 - LR:0.0003 - train_loss: 1.983Step 3011/953240 - LR:0.0030 - train_loss: 2.018Step 3021/953240 - LR:0.0003 - train_loss: 1.961Step 3031/953240 - LR:0.0030 - train_loss: 2.011Step 3041/953240 - LR:0.0003 - train_loss: 2.006Step 3051/953240 - LR:0.0030 - train_loss: 1.982Step 3061/953240 - LR:0.0003 - train_loss: 1.978Step 3071/953240 - LR:0.0030 - train_loss: 2.024Step 3081/953240 - LR:0.0003 - train_loss: 1.986Step 3091/953240 - LR:0.0030 - train_loss: 1.992Step 3101/953240 - LR:0.0003 - train_loss: 1.997Step 3111/953240 - LR:0.0030 - train_loss: 1.998Step 3121/953240 - LR:0.0003 - train_loss: 1.968Step 3131/953240 - LR:0.0030 - train_loss: 1.972Step 3141/953240 - LR:0.0003 - train_loss: 2.015Step 3151/953240 - LR:0.0030 - train_loss: 1.981Step 3161/953240 - LR:0.0003 - train_loss: 1.965Step 3171/953240 - LR:0.0030 - train_loss: 1.957Step 3181/953240 - LR:0.0003 - train_loss: 1.955Step 3191/953240 - LR:0.0030 - train_loss: 1.969Step 3201/953240 - LR:0.0003 - train_loss: 1.972Step 3211/953240 - LR:0.0030 - train_loss: 2.000Step 3221/953240 - LR:0.0003 - train_loss: 1.965Step 3231/953240 - LR:0.0030 - train_loss: 1.978Step 3241/953240 - LR:0.0003 - train_loss: 2.008Step 3251/953240 - LR:0.0030 - train_loss: 1.984Step 3261/953240 - LR:0.0003 - train_loss: 1.978Step 3271/953240 - LR:0.0030 - train_loss: 1.967Step 3281/953240 - LR:0.0003 - train_loss: 1.963Step 3291/953240 - LR:0.0030 - train_loss: 1.980Step 3301/953240 - LR:0.0003 - train_loss: 1.970Step 3311/953240 - LR:0.0030 - train_loss: 1.959Step 3321/953240 - LR:0.0003 - train_loss: 1.979Step 3331/953240 - LR:0.0030 - train_loss: 1.964Step 3341/953240 - LR:0.0003 - train_loss: 2.002Step 3351/953240 - LR:0.0030 - train_loss: 1.989Step 3361/953240 - LR:0.0003 - train_loss: 1.961Step 3371/953240 - LR:0.0030 - train_loss: 1.970Step 3381/953240 - LR:0.0003 - train_loss: 1.968Step 3391/953240 - LR:0.0030 - train_loss: 1.960Step 3401/953240 - LR:0.0003 - train_loss: 1.967Step 3411/953240 - LR:0.0030 - train_loss: 1.987Step 3421/953240 - LR:0.0003 - train_loss: 1.969Step 3431/953240 - LR:0.0030 - train_loss: 1.922Step 3441/953240 - LR:0.0003 - train_loss: 1.967Step 3451/953240 - LR:0.0030 - train_loss: 1.982Step 3461/953240 - LR:0.0003 - train_loss: 1.984Step 3471/953240 - LR:0.0030 - train_loss: 1.948Step 3481/953240 - LR:0.0003 - train_loss: 1.982Step 3491/953240 - LR:0.0030 - train_loss: 2.004Step 3501/953240 - LR:0.0003 - train_loss: 1.978Step 3511/953240 - LR:0.0030 - train_loss: 1.956Step 3521/953240 - LR:0.0003 - train_loss: 1.970Step 3531/953240 - LR:0.0030 - train_loss: 1.965Step 3541/953240 - LR:0.0003 - train_loss: 1.944Step 3551/953240 - LR:0.0030 - train_loss: 1.925Step 3561/953240 - LR:0.0003 - train_loss: 1.999Step 3571/953240 - LR:0.0030 - train_loss: 1.963Step 3581/953240 - LR:0.0003 - train_loss: 1.973Step 3591/953240 - LR:0.0030 - train_loss: 2.014Step 3601/953240 - LR:0.0003 - train_loss: 1.985Step 3611/953240 - LR:0.0030 - train_loss: 1.985Step 3621/953240 - LR:0.0003 - train_loss: 1.981Step 3631/953240 - LR:0.0030 - train_loss: 1.993Step 3641/953240 - LR:0.0003 - train_loss: 1.970Step 3651/953240 - LR:0.0030 - train_loss: 1.967Step 3661/953240 - LR:0.0003 - train_loss: 1.969Step 3671/953240 - LR:0.0030 - train_loss: 1.975Step 3681/953240 - LR:0.0003 - train_loss: 1.972Step 3691/953240 - LR:0.0030 - train_loss: 1.995Step 3701/953240 - LR:0.0003 - train_loss: 1.988Step 3711/953240 - LR:0.0030 - train_loss: 1.985Step 3721/953240 - LR:0.0003 - train_loss: 1.974Step 3731/953240 - LR:0.0030 - train_loss: 1.990Step 3741/953240 - LR:0.0003 - train_loss: 1.985Step 3751/953240 - LR:0.0030 - train_loss: 1.966Step 3761/953240 - LR:0.0003 - train_loss: 1.963Step 3771/953240 - LR:0.0030 - train_loss: 1.960Step 3781/953240 - LR:0.0003 - train_loss: 1.961Step 3791/953240 - LR:0.0030 - train_loss: 2.002Step 3801/953240 - LR:0.0003 - train_loss: 1.959Step 3811/953240 - LR:0.0030 - train_loss: 1.949Step 3821/953240 - LR:0.0003 - train_loss: 1.931Step 3831/953240 - LR:0.0030 - train_loss: 1.962Step 3841/953240 - LR:0.0003 - train_loss: 1.969Step 3851/953240 - LR:0.0030 - train_loss: 1.975Step 3861/953240 - LR:0.0003 - train_loss: 1.954Step 3871/953240 - LR:0.0030 - train_loss: 1.967Step 3881/953240 - LR:0.0003 - train_loss: 1.935Step 3891/953240 - LR:0.0030 - train_loss: 1.962Step 3901/953240 - LR:0.0003 - train_loss: 1.957Step 3911/953240 - LR:0.0030 - train_loss: 1.938Step 3921/953240 - LR:0.0003 - train_loss: 1.965Step 3931/953240 - LR:0.0030 - train_loss: 1.950Step 3941/953240 - LR:0.0003 - train_loss: 1.942Step 3951/953240 - LR:0.0030 - train_loss: 1.922Step 3961/953240 - LR:0.0003 - train_loss: 1.989Step 3971/953240 - LR:0.0030 - train_loss: 1.929Step 3981/953240 - LR:0.0003 - train_loss: 1.957Step 3991/953240 - LR:0.0030 - train_loss: 1.970Step 4001/953240 - LR:0.0003 - train_loss: 1.967Step 4011/953240 - LR:0.0030 - train_loss: 1.949Step 4021/953240 - LR:0.0003 - train_loss: 1.928Step 4031/953240 - LR:0.0030 - train_loss: 1.948Step 4041/953240 - LR:0.0003 - train_loss: 1.938Step 4051/953240 - LR:0.0030 - train_loss: 1.942Step 4061/953240 - LR:0.0003 - train_loss: 1.971Step 4071/953240 - LR:0.0030 - train_loss: 1.965Step 4081/953240 - LR:0.0003 - train_loss: 1.990Step 4091/953240 - LR:0.0030 - train_loss: 1.947Step 4101/953240 - LR:0.0003 - train_loss: 1.932Step 4111/953240 - LR:0.0030 - train_loss: 1.953Step 4121/953240 - LR:0.0003 - train_loss: 1.963Step 4131/953240 - LR:0.0030 - train_loss: 1.954Step 4141/953240 - LR:0.0003 - train_loss: 1.924Step 4151/953240 - LR:0.0030 - train_loss: 1.913Step 4161/953240 - LR:0.0003 - train_loss: 1.960Step 4171/953240 - LR:0.0030 - train_loss: 1.957Step 4181/953240 - LR:0.0003 - train_loss: 1.948Step 4191/953240 - LR:0.0030 - train_loss: 1.954Step 4201/953240 - LR:0.0003 - train_loss: 1.966Step 4211/953240 - LR:0.0030 - train_loss: 1.959Step 4221/953240 - LR:0.0003 - train_loss: 1.944Step 4231/953240 - LR:0.0030 - train_loss: 1.935Step 4241/953240 - LR:0.0003 - train_loss: 1.995Step 4251/953240 - LR:0.0030 - train_loss: 1.958Step 4261/953240 - LR:0.0003 - train_loss: 1.999Step 4271/953240 - LR:0.0030 - train_loss: 1.959Step 4281/953240 - LR:0.0003 - train_loss: 1.969Step 4291/953240 - LR:0.0030 - train_loss: 1.954Step 4301/953240 - LR:0.0003 - train_loss: 1.958Step 4311/953240 - LR:0.0030 - train_loss: 1.975Step 4321/953240 - LR:0.0003 - train_loss: 1.947Step 4331/953240 - LR:0.0030 - train_loss: 1.965Step 4341/953240 - LR:0.0003 - train_loss: 1.960Step 4351/953240 - LR:0.0030 - train_loss: 1.950Step 4361/953240 - LR:0.0003 - train_loss: 1.958Step 4371/953240 - LR:0.0030 - train_loss: 1.951Step 4381/953240 - LR:0.0003 - train_loss: 1.918Step 4391/953240 - LR:0.0030 - train_loss: 1.935Step 4401/953240 - LR:0.0003 - train_loss: 1.974Step 4411/953240 - LR:0.0030 - train_loss: 1.912Step 4421/953240 - LR:0.0003 - train_loss: 1.931Step 4431/953240 - LR:0.0030 - train_loss: 1.912Step 4441/953240 - LR:0.0003 - train_loss: 1.955Step 4451/953240 - LR:0.0030 - train_loss: 1.949Step 4461/953240 - LR:0.0003 - train_loss: 1.943Step 4471/953240 - LR:0.0030 - train_loss: 1.916Step 4481/953240 - LR:0.0003 - train_loss: 1.950Step 4491/953240 - LR:0.0030 - train_loss: 1.947Step 4501/953240 - LR:0.0003 - train_loss: 1.923Step 4511/953240 - LR:0.0030 - train_loss: 1.929Step 4521/953240 - LR:0.0003 - train_loss: 1.952Step 4531/953240 - LR:0.0030 - train_loss: 1.952Step 4541/953240 - LR:0.0003 - train_loss: 1.930Step 4551/953240 - LR:0.0030 - train_loss: 1.927Step 4561/953240 - LR:0.0003 - train_loss: 1.911Step 4571/953240 - LR:0.0030 - train_loss: 1.943Step 4581/953240 - LR:0.0003 - train_loss: 1.922Step 4591/953240 - LR:0.0030 - train_loss: 1.963Step 4601/953240 - LR:0.0003 - train_loss: 1.955Step 4611/953240 - LR:0.0030 - train_loss: 1.934Step 4621/953240 - LR:0.0003 - train_loss: 1.916Step 4631/953240 - LR:0.0030 - train_loss: 1.932Step 4641/953240 - LR:0.0003 - train_loss: 1.937Step 4651/953240 - LR:0.0030 - train_loss: 1.918Step 4661/953240 - LR:0.0003 - train_loss: 1.912Step 4671/953240 - LR:0.0030 - train_loss: 1.938Step 4681/953240 - LR:0.0003 - train_loss: 1.934Step 4691/953240 - LR:0.0030 - train_loss: 1.921Step 4701/953240 - LR:0.0003 - train_loss: 1.968Step 4711/953240 - LR:0.0030 - train_loss: 1.931Step 4721/953240 - LR:0.0003 - train_loss: 1.972Step 4731/953240 - LR:0.0030 - train_loss: 1.919Step 4741/953240 - LR:0.0003 - train_loss: 1.928Step 4751/953240 - LR:0.0030 - train_loss: 1.928Step 4761/953240 - LR:0.0003 - train_loss: 1.962Step 4771/953240 - LR:0.0030 - train_loss: 1.950Step 4781/953240 - LR:0.0003 - train_loss: 2.004Step 4791/953240 - LR:0.0030 - train_loss: 1.984Step 4801/953240 - LR:0.0003 - train_loss: 1.918Step 4811/953240 - LR:0.0030 - train_loss: 1.937Step 4821/953240 - LR:0.0003 - train_loss: 1.954Step 4831/953240 - LR:0.0030 - train_loss: 1.940Step 4841/953240 - LR:0.0003 - train_loss: 1.948Step 4851/953240 - LR:0.0030 - train_loss: 1.962Step 4861/953240 - LR:0.0003 - train_loss: 1.926Step 4871/953240 - LR:0.0030 - train_loss: 1.960Step 4881/953240 - LR:0.0003 - train_loss: 1.944Step 4891/953240 - LR:0.0030 - train_loss: 1.953Step 4901/953240 - LR:0.0003 - train_loss: 1.894Step 4911/953240 - LR:0.0030 - train_loss: 1.938Step 4921/953240 - LR:0.0003 - train_loss: 1.937Step 4931/953240 - LR:0.0030 - train_loss: 1.932Step 4941/953240 - LR:0.0003 - train_loss: 1.947Step 4951/953240 - LR:0.0030 - train_loss: 1.940Step 4961/953240 - LR:0.0003 - train_loss: 1.934Step 4971/953240 - LR:0.0030 - train_loss: 1.969Step 4981/953240 - LR:0.0003 - train_loss: 1.936Step 4991/953240 - LR:0.0030 - train_loss: 1.918Step 5001/953240 - LR:0.0003 - train_loss: 1.943
exit train!
Once upon a time, Tom is very hungry, but he doesn't like the people. The moral of the story is that, it is not a good way. It with patience and care, the two of lifes and protecting all the places. < there were two friends, Ben and Joe, who werenled. They were walking around the world and the feelings as the rabbits was having so much time. Suddenly, one of the rabbits stopped and looked at their eyes. Its its eyes were wide and the other was so wide that it started to shake. Tom and Joe were so surprised that they ran away. They both ran back to their homes and hugged each other. The moral of the story is that it's important to be kind to others and to always stay away from them. 

I like apple, but Lily loves. I'm just me and you're getting in, it is not to be too late." Lily smiled, feeling her tears and hugged her. She was so excited that she hugged and thanked her for the surprise. The moral of the story is that it is much more than ever and it'sning. 

Once upon a time, there is a boy named lucius. He had been and he had been on his en, he had been with the cold and was very sad. The next day, the boy was exhausted. He had been on his trip to the bathroom and had to go to the bathroom. He had to stay in his room, not in his own arms and could not move. The moral of the story is that it is much more important than to be so clumsy. It is better to be free than to be in trouble. 

Once upon a time, there is a girl named xwx. One day, she was very scared and started to scare. Suddenly, the shaking began to g and en away, and the two of a white bring. Theirling was ding and seemed very funny. Suddenly, the weather started to rain. Everyone in the park was too wet and the ground was cold. "Oh no!" said Fire. Theirling was gone and the two of them disappeared. The friends was so sad that their marriage ended! 

I love the monkey, but my little friend isning by. He has been, just meging, and the other boy is gusing. Noh, come and ene-ee, and their-ee, and the two of the bluew. The moral of the story, it is not a lovely day. It isn to be the first time, but not always about how much you want. 

Once upon a time, there is a monkey named dada. He was coming up to the park with the small brags. When he arrived, he smiled and said, "We weren by our arms. We should always that." His mom and Dad looked at the little prepable and said, "We're getting in trouble. We need to be more careful when we go. We don't want to get lost again." The little  ⁇  year old, his heart beating in his heart. He smiled as he watched the little animals in the sky. He knew he would never forget the little monkey and the little girl. 

Once upon a time, the sun is dimmed. The moral of the story is to be too late, so you can be more late. 

Once upon a time, the water is dirty. "Look, I'm apo, I'm aw," said Jill. The two ofns shook, but the coldness was still and it was still his breathing. The cold was over, and the cold chusing was ally. When it lay, it started to move and the snow is still in the air. The cold feelings slowly began to open and the warm air stopped. It grew bigger and bigger until it was all around the world. Jill had lots of fun playing in the snow. She was so happy that it was time to go home. 

Once upon a time, sophia won the first prize in the competition. "Have, Is!" said Steve. He was so excited that he couldn't believe the little birds. The next day, the bear came to the garden and handed the reay to the little birds. "In how it goes up," he said. The two of Stevens, the little chie-tirll and then said, "It is my pleasure," The chievity stayed pound, laughing and clapping. 

Once upon a time, there was a little girl named Lucy. She had a pet cat named Tom. "Oh, what are you doing?" asked Lucy. "I'm having a lot and protecting," replied George. The moral of the story is a bit of the world, and the family had been to Lucy's trip. 

Once upon a time, there was a little brown dog named Spot. Max was so excited that he started into the family'sry. The two friends watched as Max and Bear had been in the blue car. They had been too late, and the two of the reelling. Max had been in his first time, and the two of them had been too late. 

Once upon a time, there was a little boy named Tom. Tom quickly and the two friends quickly ass them. Eventually, the two of them continued to stay, and the two ofns. It was large and soon, and the two of adies was gone. The two friends had been alltle and had been the next day. 

Once upon a time, there was a big whale. The two horses was so much to the family that the family had to be in. The family was so scared and started to panic. The cheerful couple had been and the family was too late. The family had to go to their destination, and they had to go home. The family was very sad and scared. 

Once upon a time, there was a bunny!. <, the little bear was very upset. He didn't understand why, and he decided to do something. He put the bear back and went to the living room to help the little animals. The moral of the story is that, when you open, always and to be kind. Even, the little bear can be jealous of what you have. 

Once upon a time, and his voice was too. <, Tom and his parents were alltys in the forest. They had been in their h and were very quiet. Suddenly, the exreen appeared in the middle of the woods. His parents watched and said, "Oh no! I got all my attention and started to preusing!" Tom's parents quickly comforted him. The experts had been so much awing voice and his parents were very relieved. Tom and his parents spent the rest of the day in the forest. It was a wonderful day and Tom was happy that he had been able to have a good time. 

Once, and his heart was badly and sreling, so he to take the birle. The moral of the story is that, leting and having fun with his prepar. Doing, the two friends were very competitive and fighting. "Ice, obel, whatever?" asked Girre. Their friend looked at them and said, "I think you can be very quiet, but I can't!" Girre smiled and said, "Oh, I know you are so shy. I am always here to take you away." The moral of this story is that it's okay to be shy, but it's important to be kind and not hurt someone. 

Tim and Lily were playing in the park. The moral of the story isused, the curious neighbor is an extra dog. 

Tom had a coin that he liked very much. The next day, they gave up that and weren over the building. The hoay thanked Bear, and just the thusiing flew away in their tr. 

Tim and Mia like to play in the backyard. The two friends, the black bear, and the angry bear, came over to them. Everyone, to the white dog, ex-used the twins in the car. They all stopped and looked away around. In the morning, the white dog was singing their faces and playing with his friends in the morning. Everyone was so happy that they had been waiting for the quarrel. Everyone in the park was so impressed and they all hugged the white dog. The two friends played with the white bear and laughed. They had so much fun that they decided they wanted to come back to the park again soon. 

Tom and Mia went to the zoo with Mom and Dad. The next day, the quiet was over and the family filled with coldsss. They had come from them and had ton him. They were so scared and wished for days. Tom and Sue were so lucky to have suchely that they had been all day. They hugged and thanked the park for being suchen and for the rest of the day. 

Anna liked to speak to her toys. <, the little bear, gling, and az. It, ar, letss and anger from their arms. The family was scared and had tore. Sam was so scared that he almost fell into the cold. He was a bit scared and started to cry. Suddenly, a voice popped in his eye. It was Sam's friend, who was in trouble. He had come to help him and he said, "Don't worry, Sam. I'm here to help you. Don't worry, I'll find you. Come with me, Sam." Sam reassured the heart and picked it up. It was a small kitten! Sam was so excited to see it. He said, "Thank you. You're very kind and generous." Sam smiled and said, "You're welcome, Sam. I'm glad you're O ⁇ . I'm glad we found it." 

Lily was playing with her doll in the garden. The moral of the story, it always is a rerey. Ifed and it is sreely, and it is ally and sreely. <, Lily was sleeping and still, feelings and fearing. She had been too late. She had lost in the morning and had to stay in her arms. 

lucius likes to talk about politics. Max and his parents weren for the bus. <, Max was still on the en and found in the dark. He had been to the gus and was very sad. He had been too late for a long time. Suddenly, the ground began to shake. "Oh no!" Max said. He had been too late and the grumble. Max's parents hugged him and said, "It's okay, Max. Let's come back and see if we can find another spot." Max was so excited to see the spot. When they got back, Max ran back to the park. He saw a bench nearby and approached it. He bent down and sat down to take a seat. He looked around and noticed a few birds perched on a bench. Max said, "Hello there, little one. What's your name?" The birds chirped and they flew away. Max was so happy and he thanked them for his help. He flew back to his home, feeling happy and content. 

sophia never eats breakfast. The next time was over, and the poor was ready quickly. The family was so surprised that and asked the racess to the cat. Everyone felt a little embarrassed, but he agreed. The family had been alone and the family was much a lot. They had been all of the family's life and the family was very calmly. The family had been had to go away and the family was no longer scared. 

Lucy tell a weird story. When the emergency was over, Jack'sreen and quickly became a cold. He was a bit of the hot, but he knew that the land was full and it had been to him. The moral of the story is that, it is important to stay with it and to always it. It, don't be too late, and it's always important to us. 

Lucy and Lily are playing computer games. "Come back, let me," said Max, feelinginging. "I want to show you something," said Lily. "In with my little little bear," replied Max. Lily smiled and thanked him for the special moment. From then on, she was always with her, and she had been in her heart. 

checkpoint saved!
Executing command >>>> 
   srun --pty -c 10 -p makkapakka --export=ALL --gpus=1  ./run.sh

