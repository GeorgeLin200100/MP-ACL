Python 3.12.5
['▁<', '|', 'endo', 'f', 'text', '|', '>']
[37, 17, 39, 34, 40, 17, 38]
['▁P', 'r', 'o', 'j', 'e', 'c', 't', '▁for', '▁the', '▁art', 'if', 'ic', 'i', 'al', '▁in', 't', 'e', 'll', 'ig', 'en', 'ce', '▁class', '▁in', '▁F', 'u', 'd', 'an', '.']
torch.Size([512, 128]) torch.Size([512, 128])
The <|endoftext|> id is : 1
total params: 24,142,080
model size: 92.470MB
Training on cuda.
Epoch 1/1:
Step 1/9637 - LR:0.0000 - train_loss: 8.490Step 11/9637 - LR:0.0000 - train_loss: 7.177Step 21/9637 - LR:0.0000 - train_loss: 6.751Step 31/9637 - LR:0.0000 - train_loss: 6.344Step 41/9637 - LR:0.0000 - train_loss: 6.032Step 51/9637 - LR:0.0000 - train_loss: 5.878Step 61/9637 - LR:0.0000 - train_loss: 5.524Step 71/9637 - LR:0.0000 - train_loss: 5.320Step 81/9637 - LR:0.0000 - train_loss: 5.151Step 91/9637 - LR:0.0000 - train_loss: 4.937Step 101/9637 - LR:0.0000 - train_loss: 4.826Step 111/9637 - LR:0.0000 - train_loss: 4.715Step 121/9637 - LR:0.0000 - train_loss: 4.581Step 131/9637 - LR:0.0000 - train_loss: 4.443Step 141/9637 - LR:0.0000 - train_loss: 4.378Step 151/9637 - LR:0.0000 - train_loss: 4.275Step 161/9637 - LR:0.0000 - train_loss: 4.214Step 171/9637 - LR:0.0000 - train_loss: 4.136Step 181/9637 - LR:0.0000 - train_loss: 4.097Step 191/9637 - LR:0.0000 - train_loss: 4.018Step 201/9637 - LR:0.0000 - train_loss: 3.937Step 211/9637 - LR:0.0000 - train_loss: 3.932Step 221/9637 - LR:0.0000 - train_loss: 3.912Step 231/9637 - LR:0.0000 - train_loss: 3.818Step 241/9637 - LR:0.0000 - train_loss: 3.779Step 251/9637 - LR:0.0000 - train_loss: 3.776Step 261/9637 - LR:0.0000 - train_loss: 3.737Step 271/9637 - LR:0.0000 - train_loss: 3.686Step 281/9637 - LR:0.0000 - train_loss: 3.661Step 291/9637 - LR:0.0000 - train_loss: 3.621Step 301/9637 - LR:0.0000 - train_loss: 3.638Step 311/9637 - LR:0.0000 - train_loss: 3.559Step 321/9637 - LR:0.0000 - train_loss: 3.538Step 331/9637 - LR:0.0000 - train_loss: 3.527Step 341/9637 - LR:0.0000 - train_loss: 3.481Step 351/9637 - LR:0.0000 - train_loss: 3.459Step 361/9637 - LR:0.0000 - train_loss: 3.445Step 371/9637 - LR:0.0000 - train_loss: 3.423Step 381/9637 - LR:0.0000 - train_loss: 3.406Step 391/9637 - LR:0.0000 - train_loss: 3.368Step 401/9637 - LR:0.0000 - train_loss: 3.397Step 411/9637 - LR:0.0000 - train_loss: 3.356Step 421/9637 - LR:0.0000 - train_loss: 3.322Step 431/9637 - LR:0.0000 - train_loss: 3.348Step 441/9637 - LR:0.0000 - train_loss: 3.267Step 451/9637 - LR:0.0000 - train_loss: 3.266Step 461/9637 - LR:0.0000 - train_loss: 3.219Step 471/9637 - LR:0.0000 - train_loss: 3.251Step 481/9637 - LR:0.0000 - train_loss: 3.234Step 491/9637 - LR:0.0000 - train_loss: 3.249Step 501/9637 - LR:0.0000 - train_loss: 3.223Step 511/9637 - LR:0.0000 - train_loss: 3.178Step 521/9637 - LR:0.0000 - train_loss: 3.190Step 531/9637 - LR:0.0000 - train_loss: 3.189Step 541/9637 - LR:0.0000 - train_loss: 3.133Step 551/9637 - LR:0.0000 - train_loss: 3.128Step 561/9637 - LR:0.0000 - train_loss: 3.114Step 571/9637 - LR:0.0000 - train_loss: 3.116Step 581/9637 - LR:0.0000 - train_loss: 3.099Step 591/9637 - LR:0.0000 - train_loss: 3.081Step 601/9637 - LR:0.0000 - train_loss: 3.052Step 611/9637 - LR:0.0000 - train_loss: 3.030Step 621/9637 - LR:0.0000 - train_loss: 3.044Step 631/9637 - LR:0.0000 - train_loss: 3.009Step 641/9637 - LR:0.0000 - train_loss: 3.024Step 651/9637 - LR:0.0000 - train_loss: 3.006Step 661/9637 - LR:0.0000 - train_loss: 2.978Step 671/9637 - LR:0.0000 - train_loss: 2.998Step 681/9637 - LR:0.0000 - train_loss: 2.932Step 691/9637 - LR:0.0000 - train_loss: 2.988Step 701/9637 - LR:0.0000 - train_loss: 2.955Step 711/9637 - LR:0.0000 - train_loss: 2.942Step 721/9637 - LR:0.0000 - train_loss: 2.921Step 731/9637 - LR:0.0000 - train_loss: 2.929Step 741/9637 - LR:0.0000 - train_loss: 2.902Step 751/9637 - LR:0.0000 - train_loss: 2.931Step 761/9637 - LR:0.0000 - train_loss: 2.871Step 771/9637 - LR:0.0000 - train_loss: 2.891Step 781/9637 - LR:0.0000 - train_loss: 2.857Step 791/9637 - LR:0.0000 - train_loss: 2.832Step 801/9637 - LR:0.0000 - train_loss: 2.831Step 811/9637 - LR:0.0000 - train_loss: 2.835Step 821/9637 - LR:0.0000 - train_loss: 2.817Step 831/9637 - LR:0.0000 - train_loss: 2.829Step 841/9637 - LR:0.0000 - train_loss: 2.792Step 851/9637 - LR:0.0000 - train_loss: 2.823Step 861/9637 - LR:0.0000 - train_loss: 2.789Step 871/9637 - LR:0.0000 - train_loss: 2.760Step 881/9637 - LR:0.0000 - train_loss: 2.781Step 891/9637 - LR:0.0000 - train_loss: 2.758Step 901/9637 - LR:0.0000 - train_loss: 2.783Step 911/9637 - LR:0.0000 - train_loss: 2.776Step 921/9637 - LR:0.0000 - train_loss: 2.739Step 931/9637 - LR:0.0000 - train_loss: 2.754Step 941/9637 - LR:0.0000 - train_loss: 2.735Step 951/9637 - LR:0.0000 - train_loss: 2.707Step 961/9637 - LR:0.0000 - train_loss: 2.744Step 971/9637 - LR:0.0000 - train_loss: 2.709Step 981/9637 - LR:0.0000 - train_loss: 2.718Step 991/9637 - LR:0.0000 - train_loss: 2.687Step 1001/9637 - LR:0.0000 - train_loss: 2.681Step 1011/9637 - LR:0.0000 - train_loss: 2.691Step 1021/9637 - LR:0.0000 - train_loss: 2.702Step 1031/9637 - LR:0.0000 - train_loss: 2.676Step 1041/9637 - LR:0.0000 - train_loss: 2.670Step 1051/9637 - LR:0.0000 - train_loss: 2.609Step 1061/9637 - LR:0.0000 - train_loss: 2.614Step 1071/9637 - LR:0.0000 - train_loss: 2.642Step 1081/9637 - LR:0.0000 - train_loss: 2.651Step 1091/9637 - LR:0.0000 - train_loss: 2.617Step 1101/9637 - LR:0.0000 - train_loss: 2.605Step 1111/9637 - LR:0.0000 - train_loss: 2.600Step 1121/9637 - LR:0.0000 - train_loss: 2.613Step 1131/9637 - LR:0.0000 - train_loss: 2.567Step 1141/9637 - LR:0.0000 - train_loss: 2.622Step 1151/9637 - LR:0.0000 - train_loss: 2.599Step 1161/9637 - LR:0.0000 - train_loss: 2.596Step 1171/9637 - LR:0.0000 - train_loss: 2.594Step 1181/9637 - LR:0.0000 - train_loss: 2.576Step 1191/9637 - LR:0.0000 - train_loss: 2.606Step 1201/9637 - LR:0.0000 - train_loss: 2.555Step 1211/9637 - LR:0.0000 - train_loss: 2.561Step 1221/9637 - LR:0.0000 - train_loss: 2.550Step 1231/9637 - LR:0.0000 - train_loss: 2.515Step 1241/9637 - LR:0.0000 - train_loss: 2.516Step 1251/9637 - LR:0.0000 - train_loss: 2.558Step 1261/9637 - LR:0.0000 - train_loss: 2.547Step 1271/9637 - LR:0.0000 - train_loss: 2.542Step 1281/9637 - LR:0.0000 - train_loss: 2.522Step 1291/9637 - LR:0.0000 - train_loss: 2.507Step 1301/9637 - LR:0.0000 - train_loss: 2.495Step 1311/9637 - LR:0.0000 - train_loss: 2.482Step 1321/9637 - LR:0.0000 - train_loss: 2.460Step 1331/9637 - LR:0.0000 - train_loss: 2.481Step 1341/9637 - LR:0.0000 - train_loss: 2.499Step 1351/9637 - LR:0.0000 - train_loss: 2.470Step 1361/9637 - LR:0.0000 - train_loss: 2.500Step 1371/9637 - LR:0.0000 - train_loss: 2.440Step 1381/9637 - LR:0.0000 - train_loss: 2.475Step 1391/9637 - LR:0.0000 - train_loss: 2.462Step 1401/9637 - LR:0.0000 - train_loss: 2.499Step 1411/9637 - LR:0.0000 - train_loss: 2.444Step 1421/9637 - LR:0.0000 - train_loss: 2.474Step 1431/9637 - LR:0.0000 - train_loss: 2.449Step 1441/9637 - LR:0.0000 - train_loss: 2.457Step 1451/9637 - LR:0.0000 - train_loss: 2.457Step 1461/9637 - LR:0.0000 - train_loss: 2.427Step 1471/9637 - LR:0.0000 - train_loss: 2.432Step 1481/9637 - LR:0.0000 - train_loss: 2.433Step 1491/9637 - LR:0.0000 - train_loss: 2.403Step 1501/9637 - LR:0.0000 - train_loss: 2.448Step 1511/9637 - LR:0.0000 - train_loss: 2.390Step 1521/9637 - LR:0.0000 - train_loss: 2.396Step 1531/9637 - LR:0.0000 - train_loss: 2.443Step 1541/9637 - LR:0.0000 - train_loss: 2.440Step 1551/9637 - LR:0.0000 - train_loss: 2.424Step 1561/9637 - LR:0.0000 - train_loss: 2.373Step 1571/9637 - LR:0.0000 - train_loss: 2.397Step 1581/9637 - LR:0.0000 - train_loss: 2.375Step 1591/9637 - LR:0.0000 - train_loss: 2.392Step 1601/9637 - LR:0.0000 - train_loss: 2.376Step 1611/9637 - LR:0.0000 - train_loss: 2.393Step 1621/9637 - LR:0.0000 - train_loss: 2.355Step 1631/9637 - LR:0.0000 - train_loss: 2.388Step 1641/9637 - LR:0.0000 - train_loss: 2.381Step 1651/9637 - LR:0.0000 - train_loss: 2.414Step 1661/9637 - LR:0.0000 - train_loss: 2.355Step 1671/9637 - LR:0.0000 - train_loss: 2.323Step 1681/9637 - LR:0.0000 - train_loss: 2.348Step 1691/9637 - LR:0.0000 - train_loss: 2.387Step 1701/9637 - LR:0.0000 - train_loss: 2.376Step 1711/9637 - LR:0.0000 - train_loss: 2.363Step 1721/9637 - LR:0.0000 - train_loss: 2.328Step 1731/9637 - LR:0.0000 - train_loss: 2.324Step 1741/9637 - LR:0.0000 - train_loss: 2.345Step 1751/9637 - LR:0.0000 - train_loss: 2.324Step 1761/9637 - LR:0.0000 - train_loss: 2.334Step 1771/9637 - LR:0.0000 - train_loss: 2.322Step 1781/9637 - LR:0.0000 - train_loss: 2.322Step 1791/9637 - LR:0.0000 - train_loss: 2.333Step 1801/9637 - LR:0.0000 - train_loss: 2.304Step 1811/9637 - LR:0.0000 - train_loss: 2.299Step 1821/9637 - LR:0.0000 - train_loss: 2.303Step 1831/9637 - LR:0.0000 - train_loss: 2.309Step 1841/9637 - LR:0.0000 - train_loss: 2.328Step 1851/9637 - LR:0.0000 - train_loss: 2.294Step 1861/9637 - LR:0.0000 - train_loss: 2.268Step 1871/9637 - LR:0.0000 - train_loss: 2.302Step 1881/9637 - LR:0.0000 - train_loss: 2.290Step 1891/9637 - LR:0.0000 - train_loss: 2.308Step 1901/9637 - LR:0.0000 - train_loss: 2.272Step 1911/9637 - LR:0.0000 - train_loss: 2.299Step 1921/9637 - LR:0.0000 - train_loss: 2.280Step 1931/9637 - LR:0.0000 - train_loss: 2.278Step 1941/9637 - LR:0.0000 - train_loss: 2.285Step 1951/9637 - LR:0.0000 - train_loss: 2.275Step 1961/9637 - LR:0.0000 - train_loss: 2.260Step 1971/9637 - LR:0.0000 - train_loss: 2.287Step 1981/9637 - LR:0.0000 - train_loss: 2.270Step 1991/9637 - LR:0.0000 - train_loss: 2.238Step 2001/9637 - LR:0.0000 - train_loss: 2.268Step 2011/9637 - LR:0.0000 - train_loss: 2.248Step 2021/9637 - LR:0.0000 - train_loss: 2.253Step 2031/9637 - LR:0.0000 - train_loss: 2.257Step 2041/9637 - LR:0.0000 - train_loss: 2.239Step 2051/9637 - LR:0.0000 - train_loss: 2.231Step 2061/9637 - LR:0.0000 - train_loss: 2.244Step 2071/9637 - LR:0.0000 - train_loss: 2.225Step 2081/9637 - LR:0.0000 - train_loss: 2.234Step 2091/9637 - LR:0.0000 - train_loss: 2.246Step 2101/9637 - LR:0.0000 - train_loss: 2.221Step 2111/9637 - LR:0.0000 - train_loss: 2.229Step 2121/9637 - LR:0.0000 - train_loss: 2.223Step 2131/9637 - LR:0.0000 - train_loss: 2.230Step 2141/9637 - LR:0.0000 - train_loss: 2.202Step 2151/9637 - LR:0.0000 - train_loss: 2.206Step 2161/9637 - LR:0.0000 - train_loss: 2.206Step 2171/9637 - LR:0.0000 - train_loss: 2.200Step 2181/9637 - LR:0.0000 - train_loss: 2.220Step 2191/9637 - LR:0.0000 - train_loss: 2.203Step 2201/9637 - LR:0.0000 - train_loss: 2.210Step 2211/9637 - LR:0.0000 - train_loss: 2.208Step 2221/9637 - LR:0.0000 - train_loss: 2.229Step 2231/9637 - LR:0.0000 - train_loss: 2.225Step 2241/9637 - LR:0.0000 - train_loss: 2.193Step 2251/9637 - LR:0.0000 - train_loss: 2.221Step 2261/9637 - LR:0.0000 - train_loss: 2.206Step 2271/9637 - LR:0.0000 - train_loss: 2.179Step 2281/9637 - LR:0.0000 - train_loss: 2.146Step 2291/9637 - LR:0.0000 - train_loss: 2.188Step 2301/9637 - LR:0.0000 - train_loss: 2.162Step 2311/9637 - LR:0.0000 - train_loss: 2.171Step 2321/9637 - LR:0.0000 - train_loss: 2.168Step 2331/9637 - LR:0.0000 - train_loss: 2.175Step 2341/9637 - LR:0.0000 - train_loss: 2.202Step 2351/9637 - LR:0.0000 - train_loss: 2.171Step 2361/9637 - LR:0.0000 - train_loss: 2.178Step 2371/9637 - LR:0.0000 - train_loss: 2.163Step 2381/9637 - LR:0.0000 - train_loss: 2.117Step 2391/9637 - LR:0.0000 - train_loss: 2.171Step 2401/9637 - LR:0.0000 - train_loss: 2.159Step 2411/9637 - LR:0.0000 - train_loss: 2.171Step 2421/9637 - LR:0.0000 - train_loss: 2.185Step 2431/9637 - LR:0.0000 - train_loss: 2.147Step 2441/9637 - LR:0.0000 - train_loss: 2.129Step 2451/9637 - LR:0.0000 - train_loss: 2.138Step 2461/9637 - LR:0.0000 - train_loss: 2.123Step 2471/9637 - LR:0.0000 - train_loss: 2.131Step 2481/9637 - LR:0.0000 - train_loss: 2.163Step 2491/9637 - LR:0.0000 - train_loss: 2.126Step 2501/9637 - LR:0.0000 - train_loss: 2.100Step 2511/9637 - LR:0.0000 - train_loss: 2.130Step 2521/9637 - LR:0.0000 - train_loss: 2.142Step 2531/9637 - LR:0.0000 - train_loss: 2.125Step 2541/9637 - LR:0.0000 - train_loss: 2.115Step 2551/9637 - LR:0.0000 - train_loss: 2.124Step 2561/9637 - LR:0.0000 - train_loss: 2.097Step 2571/9637 - LR:0.0000 - train_loss: 2.121Step 2581/9637 - LR:0.0000 - train_loss: 2.122Step 2591/9637 - LR:0.0000 - train_loss: 2.144Step 2601/9637 - LR:0.0000 - train_loss: 2.103Step 2611/9637 - LR:0.0000 - train_loss: 2.110Step 2621/9637 - LR:0.0000 - train_loss: 2.096Step 2631/9637 - LR:0.0000 - train_loss: 2.107Step 2641/9637 - LR:0.0000 - train_loss: 2.076Step 2651/9637 - LR:0.0000 - train_loss: 2.081Step 2661/9637 - LR:0.0000 - train_loss: 2.112Step 2671/9637 - LR:0.0000 - train_loss: 2.107Step 2681/9637 - LR:0.0000 - train_loss: 2.091Step 2691/9637 - LR:0.0000 - train_loss: 2.081Step 2701/9637 - LR:0.0000 - train_loss: 2.119Step 2711/9637 - LR:0.0000 - train_loss: 2.115Step 2721/9637 - LR:0.0000 - train_loss: 2.112Step 2731/9637 - LR:0.0000 - train_loss: 2.110Step 2741/9637 - LR:0.0000 - train_loss: 2.079Step 2751/9637 - LR:0.0000 - train_loss: 2.086Step 2761/9637 - LR:0.0000 - train_loss: 2.065Step 2771/9637 - LR:0.0000 - train_loss: 2.079Step 2781/9637 - LR:0.0000 - train_loss: 2.099Step 2791/9637 - LR:0.0000 - train_loss: 2.100Step 2801/9637 - LR:0.0000 - train_loss: 2.086Step 2811/9637 - LR:0.0000 - train_loss: 2.080Step 2821/9637 - LR:0.0000 - train_loss: 2.066Step 2831/9637 - LR:0.0000 - train_loss: 2.090Step 2841/9637 - LR:0.0000 - train_loss: 2.054Step 2851/9637 - LR:0.0000 - train_loss: 2.082Step 2861/9637 - LR:0.0000 - train_loss: 2.086Step 2871/9637 - LR:0.0000 - train_loss: 2.038Step 2881/9637 - LR:0.0000 - train_loss: 2.020Step 2891/9637 - LR:0.0000 - train_loss: 2.068Step 2901/9637 - LR:0.0000 - train_loss: 2.042Step 2911/9637 - LR:0.0000 - train_loss: 2.052Step 2921/9637 - LR:0.0000 - train_loss: 2.073Step 2931/9637 - LR:0.0000 - train_loss: 2.036Step 2941/9637 - LR:0.0000 - train_loss: 2.045Step 2951/9637 - LR:0.0000 - train_loss: 2.062Step 2961/9637 - LR:0.0000 - train_loss: 2.039Step 2971/9637 - LR:0.0000 - train_loss: 2.053Step 2981/9637 - LR:0.0000 - train_loss: 2.021Step 2991/9637 - LR:0.0000 - train_loss: 2.037Step 3001/9637 - LR:0.0000 - train_loss: 2.044Step 3011/9637 - LR:0.0000 - train_loss: 2.056Step 3021/9637 - LR:0.0000 - train_loss: 2.057Step 3031/9637 - LR:0.0000 - train_loss: 2.042Step 3041/9637 - LR:0.0000 - train_loss: 2.048Step 3051/9637 - LR:0.0000 - train_loss: 2.028Step 3061/9637 - LR:0.0000 - train_loss: 2.021Step 3071/9637 - LR:0.0000 - train_loss: 2.032Step 3081/9637 - LR:0.0000 - train_loss: 2.004Step 3091/9637 - LR:0.0000 - train_loss: 2.005Step 3101/9637 - LR:0.0000 - train_loss: 2.023Step 3111/9637 - LR:0.0000 - train_loss: 2.037Step 3121/9637 - LR:0.0000 - train_loss: 2.012Step 3131/9637 - LR:0.0000 - train_loss: 2.026Step 3141/9637 - LR:0.0000 - train_loss: 2.036Step 3151/9637 - LR:0.0000 - train_loss: 1.995Step 3161/9637 - LR:0.0000 - train_loss: 2.029Step 3171/9637 - LR:0.0000 - train_loss: 2.002Step 3181/9637 - LR:0.0000 - train_loss: 2.042Step 3191/9637 - LR:0.0000 - train_loss: 2.009Step 3201/9637 - LR:0.0000 - train_loss: 1.991Step 3211/9637 - LR:0.0000 - train_loss: 1.977Step 3221/9637 - LR:0.0000 - train_loss: 1.999Step 3231/9637 - LR:0.0000 - train_loss: 2.019Step 3241/9637 - LR:0.0000 - train_loss: 2.038Step 3251/9637 - LR:0.0000 - train_loss: 1.993Step 3261/9637 - LR:0.0000 - train_loss: 1.981Step 3271/9637 - LR:0.0000 - train_loss: 1.999Step 3281/9637 - LR:0.0000 - train_loss: 1.998Step 3291/9637 - LR:0.0000 - train_loss: 2.021Step 3301/9637 - LR:0.0000 - train_loss: 1.978Step 3311/9637 - LR:0.0000 - train_loss: 2.002Step 3321/9637 - LR:0.0000 - train_loss: 1.974Step 3331/9637 - LR:0.0000 - train_loss: 1.990Step 3341/9637 - LR:0.0000 - train_loss: 1.973Step 3351/9637 - LR:0.0000 - train_loss: 1.981Step 3361/9637 - LR:0.0000 - train_loss: 1.995Step 3371/9637 - LR:0.0000 - train_loss: 1.980Step 3381/9637 - LR:0.0000 - train_loss: 1.984Step 3391/9637 - LR:0.0000 - train_loss: 1.975Step 3401/9637 - LR:0.0000 - train_loss: 1.991Step 3411/9637 - LR:0.0000 - train_loss: 1.970Step 3421/9637 - LR:0.0000 - train_loss: 1.969Step 3431/9637 - LR:0.0000 - train_loss: 1.960Step 3441/9637 - LR:0.0000 - train_loss: 1.976Step 3451/9637 - LR:0.0000 - train_loss: 1.969Step 3461/9637 - LR:0.0000 - train_loss: 1.939Step 3471/9637 - LR:0.0000 - train_loss: 1.951Step 3481/9637 - LR:0.0000 - train_loss: 1.941Step 3491/9637 - LR:0.0000 - train_loss: 1.944Step 3501/9637 - LR:0.0000 - train_loss: 1.977Step 3511/9637 - LR:0.0000 - train_loss: 1.974Step 3521/9637 - LR:0.0000 - train_loss: 1.978Step 3531/9637 - LR:0.0000 - train_loss: 1.949Step 3541/9637 - LR:0.0000 - train_loss: 1.947Step 3551/9637 - LR:0.0000 - train_loss: 1.965Step 3561/9637 - LR:0.0000 - train_loss: 1.938Step 3571/9637 - LR:0.0000 - train_loss: 1.951Step 3581/9637 - LR:0.0000 - train_loss: 1.963Step 3591/9637 - LR:0.0000 - train_loss: 1.977Step 3601/9637 - LR:0.0000 - train_loss: 1.963Step 3611/9637 - LR:0.0000 - train_loss: 1.964Step 3621/9637 - LR:0.0000 - train_loss: 1.941Step 3631/9637 - LR:0.0000 - train_loss: 1.946Step 3641/9637 - LR:0.0000 - train_loss: 1.917Step 3651/9637 - LR:0.0000 - train_loss: 1.977Step 3661/9637 - LR:0.0000 - train_loss: 1.937Step 3671/9637 - LR:0.0000 - train_loss: 1.918Step 3681/9637 - LR:0.0000 - train_loss: 1.931Step 3691/9637 - LR:0.0000 - train_loss: 1.932Step 3701/9637 - LR:0.0000 - train_loss: 1.943Step 3711/9637 - LR:0.0000 - train_loss: 1.948Step 3721/9637 - LR:0.0000 - train_loss: 1.940Step 3731/9637 - LR:0.0000 - train_loss: 1.929Step 3741/9637 - LR:0.0000 - train_loss: 1.960Step 3751/9637 - LR:0.0000 - train_loss: 1.925Step 3761/9637 - LR:0.0000 - train_loss: 1.925Step 3771/9637 - LR:0.0000 - train_loss: 1.901Step 3781/9637 - LR:0.0000 - train_loss: 1.943Step 3791/9637 - LR:0.0000 - train_loss: 1.893Step 3801/9637 - LR:0.0000 - train_loss: 1.884Step 3811/9637 - LR:0.0000 - train_loss: 1.914Step 3821/9637 - LR:0.0000 - train_loss: 1.915Step 3831/9637 - LR:0.0000 - train_loss: 1.942Step 3841/9637 - LR:0.0000 - train_loss: 1.926Step 3851/9637 - LR:0.0000 - train_loss: 1.917Step 3861/9637 - LR:0.0000 - train_loss: 1.922Step 3871/9637 - LR:0.0000 - train_loss: 1.914Step 3881/9637 - LR:0.0000 - train_loss: 1.896Step 3891/9637 - LR:0.0000 - train_loss: 1.871Step 3901/9637 - LR:0.0000 - train_loss: 1.926Step 3911/9637 - LR:0.0000 - train_loss: 1.901Step 3921/9637 - LR:0.0000 - train_loss: 1.919Step 3931/9637 - LR:0.0000 - train_loss: 1.914Step 3941/9637 - LR:0.0000 - train_loss: 1.903Step 3951/9637 - LR:0.0000 - train_loss: 1.877Step 3961/9637 - LR:0.0000 - train_loss: 1.930Step 3971/9637 - LR:0.0000 - train_loss: 1.877Step 3981/9637 - LR:0.0000 - train_loss: 1.903Step 3991/9637 - LR:0.0000 - train_loss: 1.916Step 4001/9637 - LR:0.0000 - train_loss: 1.884Step 4011/9637 - LR:0.0000 - train_loss: 1.888Step 4021/9637 - LR:0.0000 - train_loss: 1.894Step 4031/9637 - LR:0.0000 - train_loss: 1.926Step 4041/9637 - LR:0.0000 - train_loss: 1.885Step 4051/9637 - LR:0.0000 - train_loss: 1.863Step 4061/9637 - LR:0.0000 - train_loss: 1.879Step 4071/9637 - LR:0.0000 - train_loss: 1.875Step 4081/9637 - LR:0.0000 - train_loss: 1.888Step 4091/9637 - LR:0.0000 - train_loss: 1.873Step 4101/9637 - LR:0.0000 - train_loss: 1.875Step 4111/9637 - LR:0.0000 - train_loss: 1.900Step 4121/9637 - LR:0.0000 - train_loss: 1.910Step 4131/9637 - LR:0.0000 - train_loss: 1.883Step 4141/9637 - LR:0.0000 - train_loss: 1.877Step 4151/9637 - LR:0.0000 - train_loss: 1.873Step 4161/9637 - LR:0.0000 - train_loss: 1.850Step 4171/9637 - LR:0.0000 - train_loss: 1.875Step 4181/9637 - LR:0.0000 - train_loss: 1.867Step 4191/9637 - LR:0.0000 - train_loss: 1.888Step 4201/9637 - LR:0.0000 - train_loss: 1.887Step 4211/9637 - LR:0.0000 - train_loss: 1.883Step 4221/9637 - LR:0.0000 - train_loss: 1.891Step 4231/9637 - LR:0.0000 - train_loss: 1.855Step 4241/9637 - LR:0.0000 - train_loss: 1.844Step 4251/9637 - LR:0.0000 - train_loss: 1.854Step 4261/9637 - LR:0.0000 - train_loss: 1.854Step 4271/9637 - LR:0.0000 - train_loss: 1.853Step 4281/9637 - LR:0.0000 - train_loss: 1.852Step 4291/9637 - LR:0.0000 - train_loss: 1.839Step 4301/9637 - LR:0.0000 - train_loss: 1.849Step 4311/9637 - LR:0.0000 - train_loss: 1.826Step 4321/9637 - LR:0.0000 - train_loss: 1.842Step 4331/9637 - LR:0.0000 - train_loss: 1.853Step 4341/9637 - LR:0.0000 - train_loss: 1.851Step 4351/9637 - LR:0.0000 - train_loss: 1.845Step 4361/9637 - LR:0.0000 - train_loss: 1.849Step 4371/9637 - LR:0.0000 - train_loss: 1.845Step 4381/9637 - LR:0.0000 - train_loss: 1.859Step 4391/9637 - LR:0.0000 - train_loss: 1.829Step 4401/9637 - LR:0.0000 - train_loss: 1.832Step 4411/9637 - LR:0.0000 - train_loss: 1.842Step 4421/9637 - LR:0.0000 - train_loss: 1.816Step 4431/9637 - LR:0.0000 - train_loss: 1.801Step 4441/9637 - LR:0.0000 - train_loss: 1.839Step 4451/9637 - LR:0.0000 - train_loss: 1.846Step 4461/9637 - LR:0.0000 - train_loss: 1.841Step 4471/9637 - LR:0.0000 - train_loss: 1.834Step 4481/9637 - LR:0.0000 - train_loss: 1.809Step 4491/9637 - LR:0.0000 - train_loss: 1.842Step 4501/9637 - LR:0.0000 - train_loss: 1.851Step 4511/9637 - LR:0.0000 - train_loss: 1.829Step 4521/9637 - LR:0.0000 - train_loss: 1.812Step 4531/9637 - LR:0.0000 - train_loss: 1.832Step 4541/9637 - LR:0.0000 - train_loss: 1.828Step 4551/9637 - LR:0.0000 - train_loss: 1.854Step 4561/9637 - LR:0.0000 - train_loss: 1.822Step 4571/9637 - LR:0.0000 - train_loss: 1.805Step 4581/9637 - LR:0.0000 - train_loss: 1.781Step 4591/9637 - LR:0.0000 - train_loss: 1.847Step 4601/9637 - LR:0.0000 - train_loss: 1.818Step 4611/9637 - LR:0.0000 - train_loss: 1.797Step 4621/9637 - LR:0.0000 - train_loss: 1.805Step 4631/9637 - LR:0.0000 - train_loss: 1.827Step 4641/9637 - LR:0.0000 - train_loss: 1.825Step 4651/9637 - LR:0.0000 - train_loss: 1.808Step 4661/9637 - LR:0.0000 - train_loss: 1.805Step 4671/9637 - LR:0.0000 - train_loss: 1.811Step 4681/9637 - LR:0.0000 - train_loss: 1.840Step 4691/9637 - LR:0.0000 - train_loss: 1.814Step 4701/9637 - LR:0.0000 - train_loss: 1.797Step 4711/9637 - LR:0.0000 - train_loss: 1.831Step 4721/9637 - LR:0.0000 - train_loss: 1.821Step 4731/9637 - LR:0.0000 - train_loss: 1.796Step 4741/9637 - LR:0.0000 - train_loss: 1.813Step 4751/9637 - LR:0.0000 - train_loss: 1.784Step 4761/9637 - LR:0.0000 - train_loss: 1.801Step 4771/9637 - LR:0.0000 - train_loss: 1.795Step 4781/9637 - LR:0.0000 - train_loss: 1.789Step 4791/9637 - LR:0.0000 - train_loss: 1.801Step 4801/9637 - LR:0.0000 - train_loss: 1.808Step 4811/9637 - LR:0.0000 - train_loss: 1.809Step 4821/9637 - LR:0.0000 - train_loss: 1.789Step 4831/9637 - LR:0.0000 - train_loss: 1.765Step 4841/9637 - LR:0.0000 - train_loss: 1.792Step 4851/9637 - LR:0.0000 - train_loss: 1.773Step 4861/9637 - LR:0.0000 - train_loss: 1.791Step 4871/9637 - LR:0.0000 - train_loss: 1.787Step 4881/9637 - LR:0.0000 - train_loss: 1.777Step 4891/9637 - LR:0.0000 - train_loss: 1.767Step 4901/9637 - LR:0.0000 - train_loss: 1.776Step 4911/9637 - LR:0.0000 - train_loss: 1.763Step 4921/9637 - LR:0.0000 - train_loss: 1.788Step 4931/9637 - LR:0.0000 - train_loss: 1.796Step 4941/9637 - LR:0.0000 - train_loss: 1.808Step 4951/9637 - LR:0.0000 - train_loss: 1.781Step 4961/9637 - LR:0.0000 - train_loss: 1.775Step 4971/9637 - LR:0.0000 - train_loss: 1.793Step 4981/9637 - LR:0.0000 - train_loss: 1.784Step 4991/9637 - LR:0.0000 - train_loss: 1.780Step 5001/9637 - LR:0.0000 - train_loss: 1.756
exit train!
Once upon a time, Tom is very hungry, but he doesn't always want to get his rest. <| even though the old man was busy smiling in the bright, grumpyness. He was given some special spot to rest, and he set off with a special twig. Every day, the old man kept the gold wallet safe and never had to have a secret of all. He would never forget when it was there to help him find a place to keep his secret. 

I like apple, but Lily loves that the mostly Sparky was not feeling sad and ever to be happy. <| of course, we can find new friends and help each other, happy and strong. That's were very valuable, and we should do that too. Moral of the story ⁇  it is always good to have been responsible, and that it's safe. No matter how selfish to be mean, it is important to stay strong and have fun with it. 

Once upon a time, there is a boy named Tom. The end of need to go to school and take some time, clean and clean Pe. It was the best friend of the world. <| value was so healthy and useful. It was never invited a long, meaning place to you. 

Once upon a time, there is a girl named Lily. One day, she was very persistent and decided to take the coins. <|. So, she decided to look for the brokenness. She found the special spot, and curled up in her pocket. But then she realised that it was all of the friends to enjoy something, so that they should stay in the stable and rest. 

I love the monkey, but she promised that it is not so important to have a long time to stay up for ways to stay in getting more and more important. <| encoman was so thankful to have seen a brain. They continued looking everywhere, and sure enough, the world is perfect to stay for a little while they ran around the forest. What was the best way you could have been in the beginning, by enjoying the rest of the day and the power. 

Once upon a time, there is a monkey had been looking for the powerful deparle. <| rearted and the two of them decided to stay in the park forever. <| no one knew what to do. The moral of this story is - though you have been brave, you should never have been looking for things that belong to away. No matter how much money it is to stay safe and leave it alone." The moral of the story is that it is better to listen to grown-ups, even if we don't need grown-ups. 

Once upon a time, the sun is dimmed. < goals can it leads couragely, we must be careful and keep your wallet. No matter how selfish and mean it is was that it's always better to be kind and ahead picking out in your heart. <|endofity is a special way to stay together and take good care of yourself. Even when things don't go as planned, we should always ask before you keep ways. 

Once upon a time, the water is dirty. <| and the young little boy was so happy to have taken the thing away from the flood!" <| woman was proud of her to be having parted a happy part. She had been as kind to trust and always have the money and was never seen again. 

Once upon a time, sophia won the first prize in the competition. <| was taking a break and was so determined to stop followting the other people in the future. Just have been extra scared, we can still be able to such a beautiful friend when you have to stay together. <|endof followed the last time, the two friends decided to rest and go on an adventure to explore the old land. They held hands and became the fastest hill, going as fast as they could, and it was so much fun. The animals were so happy and so quiet that they kept going until it was time to go home. The animal thanked the animals for their help and promised never to forget the sign. The end. 

Once upon a time, there was a little girl named Lucy. She had a pet cat named Tom. <| have stayed there and being thoughtful was by asking and to come in forever. Even the old tree was a place, but Bella was careful, and did what she had been looking for. 

Once upon a time, there was a little brown dog named Spot. The end of the day, he was very careful and never wanted to be able to get his new friend. <| than anything had compliments had grown. They support each other were happy and have found a way to be happy. <|endofa set the woods. The moral of the story is that it's important to be careful when collecting things. 

Once upon a time, there was a little boy named Tom. <th of the rest of the day exploring the woods when it is sunny and full of life. <|endofaced, the little boy felt the most special friend in the forest. He would never forget his amazing adventure, and would never forget it. 

Once upon a time, there was a big whale. <| promother was so grateful to have a new friend and bonedly. <|endofly were always thankful to have been looking for the friends in the park. <|endofly thanked the bravest of hunter and went out happily. He had been lazy and had been able to protect out on such a magical adventure. 

Once upon a time, there was a kind way to get the fastest and that's not why special, the old feeling of trying to rest and stop the feeling that way. <| are racing, it's just a break, and the pence of all the trouble. But be careful, it's smile and never share with the safety of his friends. 

Once upon a time, so they can have been happy to be ready for something else and stayed together in the tree. <| no matter what, the children can be scared of being patient and tidy when being outside to help each other," she said. <| amckabled and courage that it means to take the way anywhere before going to shoot it again. 

Once?” he was no longer looking out of colour, feeling happy to have had been able to have his special time. <| from then on, he had been warned with his friends to watch over the special fox. That's do not thing that it is important to stay patient and not to take what you have before you get too handle for the best exies by chewing. 

Tim and Lily were playing in the park. <| before hiding, the old man has been like the old and olds. You must have been grown up to the crow and be a generous friend, even if it still be kind to the person who had been looking for them in a deep situation. <| have taken care of the old house so that no one should have been successful on return. Something is lucky that we are ours to stay away from all. The moral of this story is that it's important to take something that is not yours to you. 

Tom had a coin that he liked very much. <| of its wise mom's sly did a very important thing. I was sure that it is important to have you not was trying to do something famous for the rabbit to stay together. Moral of the story is that sometimes even bigger than to be doing as you donob, but not alling our courage to be friendly. Don't raise anything away and thinkMy heart is yours. It's important to never be greedy, but also to respect is the right hard what is not yours. 

Tim and Mia like to play in the backyard. <mbate and its chaped for joy to take away had been full of machines and adventures, they used the money to get a special place. <|fore exploring in the park when suddenly, the old man's heard about a group of other animals. From then on, he was careful to stay up to the frogs and stay in the bin. 

Tom and Mia went to the zoo with Mom and Dad. <| valued it of the we have been able to go faster before. This was so much fun," said Jenny. "It is such a wonderful job, but remember it was not so brave to come down. With listening, the kids had found a special place full of power and a lesson that day. 

Anna liked to speak to her toys. From then on, the grumpy man was able to get too, even stop in making sure that it can to be more careful and not play. <|endof stories can be more careful whenever the das.” <|endoftext| and the animals became friends, always have a time to play it. 

Lily was playing with her doll in the garden. <| was about chasing a playful voice, he felt much better that he had grown out to be treated and found a way to keep his money. He would take east and do the right thing. 

Tim likes to talk about politics. <m then we knew that it choices to be kind and kind. So he decided to never make sure! <|, the two of them worked together in the park every day, teaching such a lovely thing. Even when things donos will be careless, they can still be dangerous. 

Sophia never eats breakfast. <troiting was realized that it was dependable to have been more careful. Now, with care, all of its journey we don't seem to pay attention. Even, anything can be the most beautiful in yourself, because there are so kind of you. 

Lucy tell a weird story. <mared, the little rabbit was feeling very excited and so grateful to have been to have been able to build new things. <| amkingly, sometimes it's too hard to be so sure we can make things better." <|endof thought in the end of the day, the two of them set off on their adventure. 

Lucy and Lily are playing computer games. From that day you don't forget to stay close to the old man's, but it's soon not so grumpy anymore. Now, when you help, let's go play outside.” The moral of the story is that it is ok to take things that don't belong to you. It ⁇ s important being brave to stay friendly to the two people - if you don't take loyal people ⁇ s rules to keep them safe. 

checkpoint saved!
Executing command >>>> 
   srun --pty -c 10 -p makkapakka --export=ALL --gpus=5  ./run.sh

