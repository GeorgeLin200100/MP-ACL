Python 3.12.5
['▁<', '|', 'endo', 'f', 'text', '|', '>']
[37, 17, 39, 34, 40, 17, 38]
['▁P', 'r', 'o', 'j', 'e', 'c', 't', '▁for', '▁the', '▁art', 'if', 'ic', 'i', 'al', '▁in', 't', 'e', 'll', 'ig', 'en', 'ce', '▁class', '▁in', '▁F', 'u', 'd', 'an', '.']
torch.Size([512, 128]) torch.Size([512, 128])
The <|endoftext|> id is : 1
total params: 24,142,080
model size: 92.470MB
Training on cuda.
Epoch 1/1:
Step 1/9637 - LR:0.0000 - train_loss: 8.462Step 11/9637 - LR:0.0000 - train_loss: 7.206Step 21/9637 - LR:0.0000 - train_loss: 6.712Step 31/9637 - LR:0.0000 - train_loss: 6.295Step 41/9637 - LR:0.0000 - train_loss: 5.952Step 51/9637 - LR:0.0000 - train_loss: 5.615Step 61/9637 - LR:0.0000 - train_loss: 5.376Step 71/9637 - LR:0.0000 - train_loss: 5.180Step 81/9637 - LR:0.0000 - train_loss: 4.995Step 91/9637 - LR:0.0000 - train_loss: 4.842Step 101/9637 - LR:0.0000 - train_loss: 4.689Step 111/9637 - LR:0.0000 - train_loss: 4.592Step 121/9637 - LR:0.0000 - train_loss: 4.531Step 131/9637 - LR:0.0000 - train_loss: 4.405Step 141/9637 - LR:0.0000 - train_loss: 4.314Step 151/9637 - LR:0.0000 - train_loss: 4.279Step 161/9637 - LR:0.0000 - train_loss: 4.140Step 171/9637 - LR:0.0000 - train_loss: 4.155Step 181/9637 - LR:0.0000 - train_loss: 4.051Step 191/9637 - LR:0.0000 - train_loss: 4.077Step 201/9637 - LR:0.0000 - train_loss: 3.946Step 211/9637 - LR:0.0000 - train_loss: 3.890Step 221/9637 - LR:0.0000 - train_loss: 3.881Step 231/9637 - LR:0.0000 - train_loss: 3.814Step 241/9637 - LR:0.0000 - train_loss: 3.772Step 251/9637 - LR:0.0000 - train_loss: 3.736Step 261/9637 - LR:0.0000 - train_loss: 3.779Step 271/9637 - LR:0.0000 - train_loss: 3.690Step 281/9637 - LR:0.0000 - train_loss: 3.609Step 291/9637 - LR:0.0000 - train_loss: 3.589Step 301/9637 - LR:0.0000 - train_loss: 3.573Step 311/9637 - LR:0.0000 - train_loss: 3.598Step 321/9637 - LR:0.0000 - train_loss: 3.544Step 331/9637 - LR:0.0000 - train_loss: 3.493Step 341/9637 - LR:0.0000 - train_loss: 3.489Step 351/9637 - LR:0.0000 - train_loss: 3.470Step 361/9637 - LR:0.0000 - train_loss: 3.469Step 371/9637 - LR:0.0000 - train_loss: 3.431Step 381/9637 - LR:0.0000 - train_loss: 3.421Step 391/9637 - LR:0.0000 - train_loss: 3.414Step 401/9637 - LR:0.0000 - train_loss: 3.373Step 411/9637 - LR:0.0000 - train_loss: 3.304Step 421/9637 - LR:0.0000 - train_loss: 3.338Step 431/9637 - LR:0.0000 - train_loss: 3.311Step 441/9637 - LR:0.0000 - train_loss: 3.289Step 451/9637 - LR:0.0000 - train_loss: 3.276Step 461/9637 - LR:0.0000 - train_loss: 3.257Step 471/9637 - LR:0.0000 - train_loss: 3.238Step 481/9637 - LR:0.0000 - train_loss: 3.216Step 491/9637 - LR:0.0000 - train_loss: 3.200Step 501/9637 - LR:0.0000 - train_loss: 3.171Step 511/9637 - LR:0.0000 - train_loss: 3.188Step 521/9637 - LR:0.0000 - train_loss: 3.157Step 531/9637 - LR:0.0000 - train_loss: 3.153Step 541/9637 - LR:0.0000 - train_loss: 3.133Step 551/9637 - LR:0.0000 - train_loss: 3.152Step 561/9637 - LR:0.0000 - train_loss: 3.118Step 571/9637 - LR:0.0000 - train_loss: 3.100Step 581/9637 - LR:0.0000 - train_loss: 3.079Step 591/9637 - LR:0.0000 - train_loss: 3.034Step 601/9637 - LR:0.0000 - train_loss: 3.073Step 611/9637 - LR:0.0000 - train_loss: 3.053Step 621/9637 - LR:0.0000 - train_loss: 3.080Step 631/9637 - LR:0.0000 - train_loss: 2.999Step 641/9637 - LR:0.0000 - train_loss: 2.993Step 651/9637 - LR:0.0000 - train_loss: 2.974Step 661/9637 - LR:0.0000 - train_loss: 2.991Step 671/9637 - LR:0.0000 - train_loss: 2.927Step 681/9637 - LR:0.0000 - train_loss: 2.990Step 691/9637 - LR:0.0000 - train_loss: 2.967Step 701/9637 - LR:0.0000 - train_loss: 2.942Step 711/9637 - LR:0.0000 - train_loss: 2.924Step 721/9637 - LR:0.0000 - train_loss: 2.940Step 731/9637 - LR:0.0000 - train_loss: 2.936Step 741/9637 - LR:0.0000 - train_loss: 2.879Step 751/9637 - LR:0.0000 - train_loss: 2.909Step 761/9637 - LR:0.0000 - train_loss: 2.873Step 771/9637 - LR:0.0000 - train_loss: 2.858Step 781/9637 - LR:0.0000 - train_loss: 2.855Step 791/9637 - LR:0.0000 - train_loss: 2.864Step 801/9637 - LR:0.0000 - train_loss: 2.802Step 811/9637 - LR:0.0000 - train_loss: 2.845Step 821/9637 - LR:0.0000 - train_loss: 2.850Step 831/9637 - LR:0.0000 - train_loss: 2.837Step 841/9637 - LR:0.0000 - train_loss: 2.797Step 851/9637 - LR:0.0000 - train_loss: 2.783Step 861/9637 - LR:0.0000 - train_loss: 2.820Step 871/9637 - LR:0.0000 - train_loss: 2.748Step 881/9637 - LR:0.0000 - train_loss: 2.787Step 891/9637 - LR:0.0000 - train_loss: 2.772Step 901/9637 - LR:0.0000 - train_loss: 2.789Step 911/9637 - LR:0.0000 - train_loss: 2.760Step 921/9637 - LR:0.0000 - train_loss: 2.770Step 931/9637 - LR:0.0000 - train_loss: 2.702Step 941/9637 - LR:0.0000 - train_loss: 2.719Step 951/9637 - LR:0.0000 - train_loss: 2.765Step 961/9637 - LR:0.0000 - train_loss: 2.689Step 971/9637 - LR:0.0000 - train_loss: 2.712Step 981/9637 - LR:0.0000 - train_loss: 2.760Step 991/9637 - LR:0.0000 - train_loss: 2.745Step 1001/9637 - LR:0.0000 - train_loss: 2.687Step 1011/9637 - LR:0.0000 - train_loss: 2.703Step 1021/9637 - LR:0.0000 - train_loss: 2.699Step 1031/9637 - LR:0.0000 - train_loss: 2.669Step 1041/9637 - LR:0.0000 - train_loss: 2.639Step 1051/9637 - LR:0.0000 - train_loss: 2.672Step 1061/9637 - LR:0.0000 - train_loss: 2.651Step 1071/9637 - LR:0.0000 - train_loss: 2.670Step 1081/9637 - LR:0.0000 - train_loss: 2.628Step 1091/9637 - LR:0.0000 - train_loss: 2.584Step 1101/9637 - LR:0.0000 - train_loss: 2.630Step 1111/9637 - LR:0.0000 - train_loss: 2.647Step 1121/9637 - LR:0.0000 - train_loss: 2.644Step 1131/9637 - LR:0.0000 - train_loss: 2.587Step 1141/9637 - LR:0.0000 - train_loss: 2.625Step 1151/9637 - LR:0.0000 - train_loss: 2.612Step 1161/9637 - LR:0.0000 - train_loss: 2.602Step 1171/9637 - LR:0.0000 - train_loss: 2.628Step 1181/9637 - LR:0.0000 - train_loss: 2.571Step 1191/9637 - LR:0.0000 - train_loss: 2.627Step 1201/9637 - LR:0.0000 - train_loss: 2.589Step 1211/9637 - LR:0.0000 - train_loss: 2.563Step 1221/9637 - LR:0.0000 - train_loss: 2.545Step 1231/9637 - LR:0.0000 - train_loss: 2.556Step 1241/9637 - LR:0.0000 - train_loss: 2.583Step 1251/9637 - LR:0.0000 - train_loss: 2.546Step 1261/9637 - LR:0.0000 - train_loss: 2.510Step 1271/9637 - LR:0.0000 - train_loss: 2.505Step 1281/9637 - LR:0.0000 - train_loss: 2.561Step 1291/9637 - LR:0.0000 - train_loss: 2.536Step 1301/9637 - LR:0.0000 - train_loss: 2.508Step 1311/9637 - LR:0.0000 - train_loss: 2.512Step 1321/9637 - LR:0.0000 - train_loss: 2.516Step 1331/9637 - LR:0.0000 - train_loss: 2.524Step 1341/9637 - LR:0.0000 - train_loss: 2.497Step 1351/9637 - LR:0.0000 - train_loss: 2.487Step 1361/9637 - LR:0.0000 - train_loss: 2.495Step 1371/9637 - LR:0.0000 - train_loss: 2.483Step 1381/9637 - LR:0.0000 - train_loss: 2.449Step 1391/9637 - LR:0.0000 - train_loss: 2.465Step 1401/9637 - LR:0.0000 - train_loss: 2.473Step 1411/9637 - LR:0.0000 - train_loss: 2.468Step 1421/9637 - LR:0.0000 - train_loss: 2.489Step 1431/9637 - LR:0.0000 - train_loss: 2.484Step 1441/9637 - LR:0.0000 - train_loss: 2.487Step 1451/9637 - LR:0.0000 - train_loss: 2.449Step 1461/9637 - LR:0.0000 - train_loss: 2.463Step 1471/9637 - LR:0.0000 - train_loss: 2.420Step 1481/9637 - LR:0.0000 - train_loss: 2.443Step 1491/9637 - LR:0.0000 - train_loss: 2.415Step 1501/9637 - LR:0.0000 - train_loss: 2.447Step 1511/9637 - LR:0.0000 - train_loss: 2.431Step 1521/9637 - LR:0.0000 - train_loss: 2.439Step 1531/9637 - LR:0.0000 - train_loss: 2.429Step 1541/9637 - LR:0.0000 - train_loss: 2.409Step 1551/9637 - LR:0.0000 - train_loss: 2.404Step 1561/9637 - LR:0.0000 - train_loss: 2.429Step 1571/9637 - LR:0.0000 - train_loss: 2.377Step 1581/9637 - LR:0.0000 - train_loss: 2.403Step 1591/9637 - LR:0.0000 - train_loss: 2.431Step 1601/9637 - LR:0.0000 - train_loss: 2.396Step 1611/9637 - LR:0.0000 - train_loss: 2.370Step 1621/9637 - LR:0.0000 - train_loss: 2.373Step 1631/9637 - LR:0.0000 - train_loss: 2.405Step 1641/9637 - LR:0.0000 - train_loss: 2.383Step 1651/9637 - LR:0.0000 - train_loss: 2.389Step 1661/9637 - LR:0.0000 - train_loss: 2.365Step 1671/9637 - LR:0.0000 - train_loss: 2.368Step 1681/9637 - LR:0.0000 - train_loss: 2.370Step 1691/9637 - LR:0.0000 - train_loss: 2.386Step 1701/9637 - LR:0.0000 - train_loss: 2.333Step 1711/9637 - LR:0.0000 - train_loss: 2.374Step 1721/9637 - LR:0.0000 - train_loss: 2.378Step 1731/9637 - LR:0.0000 - train_loss: 2.379Step 1741/9637 - LR:0.0000 - train_loss: 2.342Step 1751/9637 - LR:0.0000 - train_loss: 2.315Step 1761/9637 - LR:0.0000 - train_loss: 2.328Step 1771/9637 - LR:0.0000 - train_loss: 2.349Step 1781/9637 - LR:0.0000 - train_loss: 2.319Step 1791/9637 - LR:0.0000 - train_loss: 2.329Step 1801/9637 - LR:0.0000 - train_loss: 2.315Step 1811/9637 - LR:0.0000 - train_loss: 2.351Step 1821/9637 - LR:0.0000 - train_loss: 2.363Step 1831/9637 - LR:0.0000 - train_loss: 2.352Step 1841/9637 - LR:0.0000 - train_loss: 2.304Step 1851/9637 - LR:0.0000 - train_loss: 2.310Step 1861/9637 - LR:0.0000 - train_loss: 2.335Step 1871/9637 - LR:0.0000 - train_loss: 2.323Step 1881/9637 - LR:0.0000 - train_loss: 2.286Step 1891/9637 - LR:0.0000 - train_loss: 2.295Step 1901/9637 - LR:0.0000 - train_loss: 2.322Step 1911/9637 - LR:0.0000 - train_loss: 2.336Step 1921/9637 - LR:0.0000 - train_loss: 2.323Step 1931/9637 - LR:0.0000 - train_loss: 2.313Step 1941/9637 - LR:0.0000 - train_loss: 2.277Step 1951/9637 - LR:0.0000 - train_loss: 2.280Step 1961/9637 - LR:0.0000 - train_loss: 2.291Step 1971/9637 - LR:0.0000 - train_loss: 2.286Step 1981/9637 - LR:0.0000 - train_loss: 2.243Step 1991/9637 - LR:0.0000 - train_loss: 2.237Step 2001/9637 - LR:0.0000 - train_loss: 2.289Step 2011/9637 - LR:0.0000 - train_loss: 2.285Step 2021/9637 - LR:0.0000 - train_loss: 2.300Step 2031/9637 - LR:0.0000 - train_loss: 2.258Step 2041/9637 - LR:0.0000 - train_loss: 2.262Step 2051/9637 - LR:0.0000 - train_loss: 2.268Step 2061/9637 - LR:0.0000 - train_loss: 2.250Step 2071/9637 - LR:0.0000 - train_loss: 2.252Step 2081/9637 - LR:0.0000 - train_loss: 2.247Step 2091/9637 - LR:0.0000 - train_loss: 2.259Step 2101/9637 - LR:0.0000 - train_loss: 2.223Step 2111/9637 - LR:0.0000 - train_loss: 2.220Step 2121/9637 - LR:0.0000 - train_loss: 2.200Step 2131/9637 - LR:0.0000 - train_loss: 2.207Step 2141/9637 - LR:0.0000 - train_loss: 2.288Step 2151/9637 - LR:0.0000 - train_loss: 2.210Step 2161/9637 - LR:0.0000 - train_loss: 2.251Step 2171/9637 - LR:0.0000 - train_loss: 2.220Step 2181/9637 - LR:0.0000 - train_loss: 2.258Step 2191/9637 - LR:0.0000 - train_loss: 2.249Step 2201/9637 - LR:0.0000 - train_loss: 2.210Step 2211/9637 - LR:0.0000 - train_loss: 2.233Step 2221/9637 - LR:0.0000 - train_loss: 2.191Step 2231/9637 - LR:0.0000 - train_loss: 2.218Step 2241/9637 - LR:0.0000 - train_loss: 2.215Step 2251/9637 - LR:0.0000 - train_loss: 2.211Step 2261/9637 - LR:0.0000 - train_loss: 2.192Step 2271/9637 - LR:0.0000 - train_loss: 2.236Step 2281/9637 - LR:0.0000 - train_loss: 2.221Step 2291/9637 - LR:0.0000 - train_loss: 2.201Step 2301/9637 - LR:0.0000 - train_loss: 2.183Step 2311/9637 - LR:0.0000 - train_loss: 2.210Step 2321/9637 - LR:0.0000 - train_loss: 2.177Step 2331/9637 - LR:0.0000 - train_loss: 2.175Step 2341/9637 - LR:0.0000 - train_loss: 2.175Step 2351/9637 - LR:0.0000 - train_loss: 2.199Step 2361/9637 - LR:0.0000 - train_loss: 2.203Step 2371/9637 - LR:0.0000 - train_loss: 2.140Step 2381/9637 - LR:0.0000 - train_loss: 2.193Step 2391/9637 - LR:0.0000 - train_loss: 2.189Step 2401/9637 - LR:0.0000 - train_loss: 2.150Step 2411/9637 - LR:0.0000 - train_loss: 2.141Step 2421/9637 - LR:0.0000 - train_loss: 2.185Step 2431/9637 - LR:0.0000 - train_loss: 2.138Step 2441/9637 - LR:0.0000 - train_loss: 2.143Step 2451/9637 - LR:0.0000 - train_loss: 2.172Step 2461/9637 - LR:0.0000 - train_loss: 2.171Step 2471/9637 - LR:0.0000 - train_loss: 2.174Step 2481/9637 - LR:0.0000 - train_loss: 2.165Step 2491/9637 - LR:0.0000 - train_loss: 2.152Step 2501/9637 - LR:0.0000 - train_loss: 2.156Step 2511/9637 - LR:0.0000 - train_loss: 2.142Step 2521/9637 - LR:0.0000 - train_loss: 2.132Step 2531/9637 - LR:0.0000 - train_loss: 2.156Step 2541/9637 - LR:0.0000 - train_loss: 2.186Step 2551/9637 - LR:0.0000 - train_loss: 2.168Step 2561/9637 - LR:0.0000 - train_loss: 2.147Step 2571/9637 - LR:0.0000 - train_loss: 2.139Step 2581/9637 - LR:0.0000 - train_loss: 2.115Step 2591/9637 - LR:0.0000 - train_loss: 2.136Step 2601/9637 - LR:0.0000 - train_loss: 2.089Step 2611/9637 - LR:0.0000 - train_loss: 2.105Step 2621/9637 - LR:0.0000 - train_loss: 2.122Step 2631/9637 - LR:0.0000 - train_loss: 2.085Step 2641/9637 - LR:0.0000 - train_loss: 2.130Step 2651/9637 - LR:0.0000 - train_loss: 2.111Step 2661/9637 - LR:0.0000 - train_loss: 2.107Step 2671/9637 - LR:0.0000 - train_loss: 2.097Step 2681/9637 - LR:0.0000 - train_loss: 2.103Step 2691/9637 - LR:0.0000 - train_loss: 2.131Step 2701/9637 - LR:0.0000 - train_loss: 2.116Step 2711/9637 - LR:0.0000 - train_loss: 2.128Step 2721/9637 - LR:0.0000 - train_loss: 2.140Step 2731/9637 - LR:0.0000 - train_loss: 2.111Step 2741/9637 - LR:0.0000 - train_loss: 2.097Step 2751/9637 - LR:0.0000 - train_loss: 2.092Step 2761/9637 - LR:0.0000 - train_loss: 2.087Step 2771/9637 - LR:0.0000 - train_loss: 2.079Step 2781/9637 - LR:0.0000 - train_loss: 2.101Step 2791/9637 - LR:0.0000 - train_loss: 2.114Step 2801/9637 - LR:0.0000 - train_loss: 2.114Step 2811/9637 - LR:0.0000 - train_loss: 2.078Step 2821/9637 - LR:0.0000 - train_loss: 2.122Step 2831/9637 - LR:0.0000 - train_loss: 2.066Step 2841/9637 - LR:0.0000 - train_loss: 2.051Step 2851/9637 - LR:0.0000 - train_loss: 2.085Step 2861/9637 - LR:0.0000 - train_loss: 2.051Step 2871/9637 - LR:0.0000 - train_loss: 2.067Step 2881/9637 - LR:0.0000 - train_loss: 2.058Step 2891/9637 - LR:0.0000 - train_loss: 2.056Step 2901/9637 - LR:0.0000 - train_loss: 2.087Step 2911/9637 - LR:0.0000 - train_loss: 2.082Step 2921/9637 - LR:0.0000 - train_loss: 2.031Step 2931/9637 - LR:0.0000 - train_loss: 2.100Step 2941/9637 - LR:0.0000 - train_loss: 2.064Step 2951/9637 - LR:0.0000 - train_loss: 2.041Step 2961/9637 - LR:0.0000 - train_loss: 2.080Step 2971/9637 - LR:0.0000 - train_loss: 2.056Step 2981/9637 - LR:0.0000 - train_loss: 2.062Step 2991/9637 - LR:0.0000 - train_loss: 2.063Step 3001/9637 - LR:0.0000 - train_loss: 2.032Step 3011/9637 - LR:0.0000 - train_loss: 2.053Step 3021/9637 - LR:0.0000 - train_loss: 2.015Step 3031/9637 - LR:0.0000 - train_loss: 2.068Step 3041/9637 - LR:0.0000 - train_loss: 2.060Step 3051/9637 - LR:0.0000 - train_loss: 2.063Step 3061/9637 - LR:0.0000 - train_loss: 2.037Step 3071/9637 - LR:0.0000 - train_loss: 2.039Step 3081/9637 - LR:0.0000 - train_loss: 2.024Step 3091/9637 - LR:0.0000 - train_loss: 2.055Step 3101/9637 - LR:0.0000 - train_loss: 2.053Step 3111/9637 - LR:0.0000 - train_loss: 2.033Step 3121/9637 - LR:0.0000 - train_loss: 2.033Step 3131/9637 - LR:0.0000 - train_loss: 2.022Step 3141/9637 - LR:0.0000 - train_loss: 2.044Step 3151/9637 - LR:0.0000 - train_loss: 2.010Step 3161/9637 - LR:0.0000 - train_loss: 2.026Step 3171/9637 - LR:0.0000 - train_loss: 2.032Step 3181/9637 - LR:0.0000 - train_loss: 2.046Step 3191/9637 - LR:0.0000 - train_loss: 2.003Step 3201/9637 - LR:0.0000 - train_loss: 2.001Step 3211/9637 - LR:0.0000 - train_loss: 2.020Step 3221/9637 - LR:0.0000 - train_loss: 2.011Step 3231/9637 - LR:0.0000 - train_loss: 2.001Step 3241/9637 - LR:0.0000 - train_loss: 2.009Step 3251/9637 - LR:0.0000 - train_loss: 1.979Step 3261/9637 - LR:0.0000 - train_loss: 2.012Step 3271/9637 - LR:0.0000 - train_loss: 1.991Step 3281/9637 - LR:0.0000 - train_loss: 1.976Step 3291/9637 - LR:0.0000 - train_loss: 2.037Step 3301/9637 - LR:0.0000 - train_loss: 1.983Step 3311/9637 - LR:0.0000 - train_loss: 1.952Step 3321/9637 - LR:0.0000 - train_loss: 2.023Step 3331/9637 - LR:0.0000 - train_loss: 1.965Step 3341/9637 - LR:0.0000 - train_loss: 1.996Step 3351/9637 - LR:0.0000 - train_loss: 1.997Step 3361/9637 - LR:0.0000 - train_loss: 1.972Step 3371/9637 - LR:0.0000 - train_loss: 1.978Step 3381/9637 - LR:0.0000 - train_loss: 1.978Step 3391/9637 - LR:0.0000 - train_loss: 1.951Step 3401/9637 - LR:0.0000 - train_loss: 1.993Step 3411/9637 - LR:0.0000 - train_loss: 1.961Step 3421/9637 - LR:0.0000 - train_loss: 1.980Step 3431/9637 - LR:0.0000 - train_loss: 1.976Step 3441/9637 - LR:0.0000 - train_loss: 1.965Step 3451/9637 - LR:0.0000 - train_loss: 1.959Step 3461/9637 - LR:0.0000 - train_loss: 1.985Step 3471/9637 - LR:0.0000 - train_loss: 1.988Step 3481/9637 - LR:0.0000 - train_loss: 1.972Step 3491/9637 - LR:0.0000 - train_loss: 1.963Step 3501/9637 - LR:0.0000 - train_loss: 1.965Step 3511/9637 - LR:0.0000 - train_loss: 1.976Step 3521/9637 - LR:0.0000 - train_loss: 1.964Step 3531/9637 - LR:0.0000 - train_loss: 1.978Step 3541/9637 - LR:0.0000 - train_loss: 1.992Step 3551/9637 - LR:0.0000 - train_loss: 1.962Step 3561/9637 - LR:0.0000 - train_loss: 1.976Step 3571/9637 - LR:0.0000 - train_loss: 1.974Step 3581/9637 - LR:0.0000 - train_loss: 1.921Step 3591/9637 - LR:0.0000 - train_loss: 1.951Step 3601/9637 - LR:0.0000 - train_loss: 1.960Step 3611/9637 - LR:0.0000 - train_loss: 1.944Step 3621/9637 - LR:0.0000 - train_loss: 1.959Step 3631/9637 - LR:0.0000 - train_loss: 1.947Step 3641/9637 - LR:0.0000 - train_loss: 1.971Step 3651/9637 - LR:0.0000 - train_loss: 1.974Step 3661/9637 - LR:0.0000 - train_loss: 1.941Step 3671/9637 - LR:0.0000 - train_loss: 1.913Step 3681/9637 - LR:0.0000 - train_loss: 1.929Step 3691/9637 - LR:0.0000 - train_loss: 1.937Step 3701/9637 - LR:0.0000 - train_loss: 1.970Step 3711/9637 - LR:0.0000 - train_loss: 1.938Step 3721/9637 - LR:0.0000 - train_loss: 1.925Step 3731/9637 - LR:0.0000 - train_loss: 1.925Step 3741/9637 - LR:0.0000 - train_loss: 1.953Step 3751/9637 - LR:0.0000 - train_loss: 1.960Step 3761/9637 - LR:0.0000 - train_loss: 1.948Step 3771/9637 - LR:0.0000 - train_loss: 1.954Step 3781/9637 - LR:0.0000 - train_loss: 1.946Step 3791/9637 - LR:0.0000 - train_loss: 1.930Step 3801/9637 - LR:0.0000 - train_loss: 1.945Step 3811/9637 - LR:0.0000 - train_loss: 1.916Step 3821/9637 - LR:0.0000 - train_loss: 1.903Step 3831/9637 - LR:0.0000 - train_loss: 1.909Step 3841/9637 - LR:0.0000 - train_loss: 1.930Step 3851/9637 - LR:0.0000 - train_loss: 1.888Step 3861/9637 - LR:0.0000 - train_loss: 1.928Step 3871/9637 - LR:0.0000 - train_loss: 1.954Step 3881/9637 - LR:0.0000 - train_loss: 1.932Step 3891/9637 - LR:0.0000 - train_loss: 1.916Step 3901/9637 - LR:0.0000 - train_loss: 1.909Step 3911/9637 - LR:0.0000 - train_loss: 1.898Step 3921/9637 - LR:0.0000 - train_loss: 1.917Step 3931/9637 - LR:0.0000 - train_loss: 1.899Step 3941/9637 - LR:0.0000 - train_loss: 1.926Step 3951/9637 - LR:0.0000 - train_loss: 1.915Step 3961/9637 - LR:0.0000 - train_loss: 1.905Step 3971/9637 - LR:0.0000 - train_loss: 1.923Step 3981/9637 - LR:0.0000 - train_loss: 1.901Step 3991/9637 - LR:0.0000 - train_loss: 1.923Step 4001/9637 - LR:0.0000 - train_loss: 1.919Step 4011/9637 - LR:0.0000 - train_loss: 1.906Step 4021/9637 - LR:0.0000 - train_loss: 1.889Step 4031/9637 - LR:0.0000 - train_loss: 1.884Step 4041/9637 - LR:0.0000 - train_loss: 1.889Step 4051/9637 - LR:0.0000 - train_loss: 1.917Step 4061/9637 - LR:0.0000 - train_loss: 1.878Step 4071/9637 - LR:0.0000 - train_loss: 1.924Step 4081/9637 - LR:0.0000 - train_loss: 1.919Step 4091/9637 - LR:0.0000 - train_loss: 1.904Step 4101/9637 - LR:0.0000 - train_loss: 1.895Step 4111/9637 - LR:0.0000 - train_loss: 1.885Step 4121/9637 - LR:0.0000 - train_loss: 1.869Step 4131/9637 - LR:0.0000 - train_loss: 1.877Step 4141/9637 - LR:0.0000 - train_loss: 1.852Step 4151/9637 - LR:0.0000 - train_loss: 1.875Step 4161/9637 - LR:0.0000 - train_loss: 1.872Step 4171/9637 - LR:0.0000 - train_loss: 1.855Step 4181/9637 - LR:0.0000 - train_loss: 1.873Step 4191/9637 - LR:0.0000 - train_loss: 1.871Step 4201/9637 - LR:0.0000 - train_loss: 1.882Step 4211/9637 - LR:0.0000 - train_loss: 1.872Step 4221/9637 - LR:0.0000 - train_loss: 1.891Step 4231/9637 - LR:0.0000 - train_loss: 1.873Step 4241/9637 - LR:0.0000 - train_loss: 1.891Step 4251/9637 - LR:0.0000 - train_loss: 1.912Step 4261/9637 - LR:0.0000 - train_loss: 1.862Step 4271/9637 - LR:0.0000 - train_loss: 1.870Step 4281/9637 - LR:0.0000 - train_loss: 1.844Step 4291/9637 - LR:0.0000 - train_loss: 1.824Step 4301/9637 - LR:0.0000 - train_loss: 1.849Step 4311/9637 - LR:0.0000 - train_loss: 1.842Step 4321/9637 - LR:0.0000 - train_loss: 1.857Step 4331/9637 - LR:0.0000 - train_loss: 1.861Step 4341/9637 - LR:0.0000 - train_loss: 1.858Step 4351/9637 - LR:0.0000 - train_loss: 1.855Step 4361/9637 - LR:0.0000 - train_loss: 1.866Step 4371/9637 - LR:0.0000 - train_loss: 1.832Step 4381/9637 - LR:0.0000 - train_loss: 1.853Step 4391/9637 - LR:0.0000 - train_loss: 1.865Step 4401/9637 - LR:0.0000 - train_loss: 1.867Step 4411/9637 - LR:0.0000 - train_loss: 1.875Step 4421/9637 - LR:0.0000 - train_loss: 1.866Step 4431/9637 - LR:0.0000 - train_loss: 1.833Step 4441/9637 - LR:0.0000 - train_loss: 1.860Step 4451/9637 - LR:0.0000 - train_loss: 1.833Step 4461/9637 - LR:0.0000 - train_loss: 1.816Step 4471/9637 - LR:0.0000 - train_loss: 1.844Step 4481/9637 - LR:0.0000 - train_loss: 1.826Step 4491/9637 - LR:0.0000 - train_loss: 1.864Step 4501/9637 - LR:0.0000 - train_loss: 1.857Step 4511/9637 - LR:0.0000 - train_loss: 1.837Step 4521/9637 - LR:0.0000 - train_loss: 1.844Step 4531/9637 - LR:0.0000 - train_loss: 1.819Step 4541/9637 - LR:0.0000 - train_loss: 1.831Step 4551/9637 - LR:0.0000 - train_loss: 1.851Step 4561/9637 - LR:0.0000 - train_loss: 1.833Step 4571/9637 - LR:0.0000 - train_loss: 1.854Step 4581/9637 - LR:0.0000 - train_loss: 1.822Step 4591/9637 - LR:0.0000 - train_loss: 1.842Step 4601/9637 - LR:0.0000 - train_loss: 1.814Step 4611/9637 - LR:0.0000 - train_loss: 1.824Step 4621/9637 - LR:0.0000 - train_loss: 1.852Step 4631/9637 - LR:0.0000 - train_loss: 1.829Step 4641/9637 - LR:0.0000 - train_loss: 1.818Step 4651/9637 - LR:0.0000 - train_loss: 1.845Step 4661/9637 - LR:0.0000 - train_loss: 1.803Step 4671/9637 - LR:0.0000 - train_loss: 1.817Step 4681/9637 - LR:0.0000 - train_loss: 1.834Step 4691/9637 - LR:0.0000 - train_loss: 1.815Step 4701/9637 - LR:0.0000 - train_loss: 1.833Step 4711/9637 - LR:0.0000 - train_loss: 1.818Step 4721/9637 - LR:0.0000 - train_loss: 1.809Step 4731/9637 - LR:0.0000 - train_loss: 1.858Step 4741/9637 - LR:0.0000 - train_loss: 1.842Step 4751/9637 - LR:0.0000 - train_loss: 1.818Step 4761/9637 - LR:0.0000 - train_loss: 1.824Step 4771/9637 - LR:0.0000 - train_loss: 1.780Step 4781/9637 - LR:0.0000 - train_loss: 1.848Step 4791/9637 - LR:0.0000 - train_loss: 1.787Step 4801/9637 - LR:0.0000 - train_loss: 1.789Step 4811/9637 - LR:0.0000 - train_loss: 1.831Step 4821/9637 - LR:0.0000 - train_loss: 1.819Step 4831/9637 - LR:0.0000 - train_loss: 1.811Step 4841/9637 - LR:0.0000 - train_loss: 1.815Step 4851/9637 - LR:0.0000 - train_loss: 1.799Step 4861/9637 - LR:0.0000 - train_loss: 1.828Step 4871/9637 - LR:0.0000 - train_loss: 1.773Step 4881/9637 - LR:0.0000 - train_loss: 1.798Step 4891/9637 - LR:0.0000 - train_loss: 1.790Step 4901/9637 - LR:0.0000 - train_loss: 1.760Step 4911/9637 - LR:0.0000 - train_loss: 1.813Step 4921/9637 - LR:0.0000 - train_loss: 1.787Step 4931/9637 - LR:0.0000 - train_loss: 1.795Step 4941/9637 - LR:0.0000 - train_loss: 1.783Step 4951/9637 - LR:0.0000 - train_loss: 1.790Step 4961/9637 - LR:0.0000 - train_loss: 1.802Step 4971/9637 - LR:0.0000 - train_loss: 1.784Step 4981/9637 - LR:0.0000 - train_loss: 1.789Step 4991/9637 - LR:0.0000 - train_loss: 1.798Step 5001/9637 - LR:0.0000 - train_loss: 1.804Step 5011/9637 - LR:0.0000 - train_loss: 1.786Step 5021/9637 - LR:0.0000 - train_loss: 1.791Step 5031/9637 - LR:0.0000 - train_loss: 1.785Step 5041/9637 - LR:0.0000 - train_loss: 1.779Step 5051/9637 - LR:0.0000 - train_loss: 1.807Step 5061/9637 - LR:0.0000 - train_loss: 1.809Step 5071/9637 - LR:0.0000 - train_loss: 1.776Step 5081/9637 - LR:0.0000 - train_loss: 1.803Step 5091/9637 - LR:0.0000 - train_loss: 1.767Step 5101/9637 - LR:0.0000 - train_loss: 1.773Step 5111/9637 - LR:0.0000 - train_loss: 1.794Step 5121/9637 - LR:0.0000 - train_loss: 1.757Step 5131/9637 - LR:0.0000 - train_loss: 1.797Step 5141/9637 - LR:0.0000 - train_loss: 1.787Step 5151/9637 - LR:0.0000 - train_loss: 1.772Step 5161/9637 - LR:0.0000 - train_loss: 1.790Step 5171/9637 - LR:0.0000 - train_loss: 1.772Step 5181/9637 - LR:0.0000 - train_loss: 1.801Step 5191/9637 - LR:0.0000 - train_loss: 1.775Step 5201/9637 - LR:0.0000 - train_loss: 1.742Step 5211/9637 - LR:0.0000 - train_loss: 1.752Step 5221/9637 - LR:0.0000 - train_loss: 1.798Step 5231/9637 - LR:0.0000 - train_loss: 1.773Step 5241/9637 - LR:0.0000 - train_loss: 1.748Step 5251/9637 - LR:0.0000 - train_loss: 1.737Step 5261/9637 - LR:0.0000 - train_loss: 1.770Step 5271/9637 - LR:0.0000 - train_loss: 1.745Step 5281/9637 - LR:0.0000 - train_loss: 1.772Step 5291/9637 - LR:0.0000 - train_loss: 1.768Step 5301/9637 - LR:0.0000 - train_loss: 1.758Step 5311/9637 - LR:0.0000 - train_loss: 1.736Step 5321/9637 - LR:0.0000 - train_loss: 1.770Step 5331/9637 - LR:0.0000 - train_loss: 1.758Step 5341/9637 - LR:0.0000 - train_loss: 1.717Step 5351/9637 - LR:0.0000 - train_loss: 1.778Step 5361/9637 - LR:0.0000 - train_loss: 1.744Step 5371/9637 - LR:0.0000 - train_loss: 1.725Step 5381/9637 - LR:0.0000 - train_loss: 1.782Step 5391/9637 - LR:0.0000 - train_loss: 1.774Step 5401/9637 - LR:0.0000 - train_loss: 1.742Step 5411/9637 - LR:0.0000 - train_loss: 1.747Step 5421/9637 - LR:0.0000 - train_loss: 1.721Step 5431/9637 - LR:0.0000 - train_loss: 1.739Step 5441/9637 - LR:0.0000 - train_loss: 1.735Step 5451/9637 - LR:0.0000 - train_loss: 1.741Step 5461/9637 - LR:0.0000 - train_loss: 1.724Step 5471/9637 - LR:0.0000 - train_loss: 1.727Step 5481/9637 - LR:0.0000 - train_loss: 1.721Step 5491/9637 - LR:0.0000 - train_loss: 1.736Step 5501/9637 - LR:0.0000 - train_loss: 1.743Step 5511/9637 - LR:0.0000 - train_loss: 1.747Step 5521/9637 - LR:0.0000 - train_loss: 1.765Step 5531/9637 - LR:0.0000 - train_loss: 1.738Step 5541/9637 - LR:0.0000 - train_loss: 1.743Step 5551/9637 - LR:0.0000 - train_loss: 1.733Step 5561/9637 - LR:0.0000 - train_loss: 1.701Step 5571/9637 - LR:0.0000 - train_loss: 1.758Step 5581/9637 - LR:0.0000 - train_loss: 1.736Step 5591/9637 - LR:0.0000 - train_loss: 1.712Step 5601/9637 - LR:0.0000 - train_loss: 1.695Step 5611/9637 - LR:0.0000 - train_loss: 1.725Step 5621/9637 - LR:0.0000 - train_loss: 1.703Step 5631/9637 - LR:0.0000 - train_loss: 1.742Step 5641/9637 - LR:0.0000 - train_loss: 1.724Step 5651/9637 - LR:0.0000 - train_loss: 1.739Step 5661/9637 - LR:0.0000 - train_loss: 1.699Step 5671/9637 - LR:0.0000 - train_loss: 1.726Step 5681/9637 - LR:0.0000 - train_loss: 1.727Step 5691/9637 - LR:0.0000 - train_loss: 1.697Step 5701/9637 - LR:0.0000 - train_loss: 1.706Step 5711/9637 - LR:0.0000 - train_loss: 1.713Step 5721/9637 - LR:0.0000 - train_loss: 1.709Step 5731/9637 - LR:0.0000 - train_loss: 1.718Step 5741/9637 - LR:0.0000 - train_loss: 1.694Step 5751/9637 - LR:0.0000 - train_loss: 1.706Step 5761/9637 - LR:0.0000 - train_loss: 1.703Step 5771/9637 - LR:0.0000 - train_loss: 1.699Step 5781/9637 - LR:0.0000 - train_loss: 1.682Step 5791/9637 - LR:0.0000 - train_loss: 1.726Step 5801/9637 - LR:0.0000 - train_loss: 1.711Step 5811/9637 - LR:0.0000 - train_loss: 1.707Step 5821/9637 - LR:0.0000 - train_loss: 1.709Step 5831/9637 - LR:0.0000 - train_loss: 1.696Step 5841/9637 - LR:0.0000 - train_loss: 1.710Step 5851/9637 - LR:0.0000 - train_loss: 1.693Step 5861/9637 - LR:0.0000 - train_loss: 1.693Step 5871/9637 - LR:0.0000 - train_loss: 1.680Step 5881/9637 - LR:0.0000 - train_loss: 1.669Step 5891/9637 - LR:0.0000 - train_loss: 1.710Step 5901/9637 - LR:0.0000 - train_loss: 1.682Step 5911/9637 - LR:0.0000 - train_loss: 1.703Step 5921/9637 - LR:0.0000 - train_loss: 1.707Step 5931/9637 - LR:0.0000 - train_loss: 1.701Step 5941/9637 - LR:0.0000 - train_loss: 1.702Step 5951/9637 - LR:0.0000 - train_loss: 1.669Step 5961/9637 - LR:0.0000 - train_loss: 1.682Step 5971/9637 - LR:0.0000 - train_loss: 1.700Step 5981/9637 - LR:0.0000 - train_loss: 1.706Step 5991/9637 - LR:0.0000 - train_loss: 1.705Step 6001/9637 - LR:0.0000 - train_loss: 1.683Step 6011/9637 - LR:0.0000 - train_loss: 1.705Step 6021/9637 - LR:0.0000 - train_loss: 1.686Step 6031/9637 - LR:0.0000 - train_loss: 1.683Step 6041/9637 - LR:0.0000 - train_loss: 1.683Step 6051/9637 - LR:0.0000 - train_loss: 1.698Step 6061/9637 - LR:0.0000 - train_loss: 1.689Step 6071/9637 - LR:0.0000 - train_loss: 1.728Step 6081/9637 - LR:0.0000 - train_loss: 1.701Step 6091/9637 - LR:0.0000 - train_loss: 1.700Step 6101/9637 - LR:0.0000 - train_loss: 1.699Step 6111/9637 - LR:0.0000 - train_loss: 1.649Step 6121/9637 - LR:0.0000 - train_loss: 1.690Step 6131/9637 - LR:0.0000 - train_loss: 1.691Step 6141/9637 - LR:0.0000 - train_loss: 1.682Step 6151/9637 - LR:0.0000 - train_loss: 1.681Step 6161/9637 - LR:0.0000 - train_loss: 1.663Step 6171/9637 - LR:0.0000 - train_loss: 1.682Step 6181/9637 - LR:0.0000 - train_loss: 1.659Step 6191/9637 - LR:0.0000 - train_loss: 1.648Step 6201/9637 - LR:0.0000 - train_loss: 1.660Step 6211/9637 - LR:0.0000 - train_loss: 1.690Step 6221/9637 - LR:0.0000 - train_loss: 1.647Step 6231/9637 - LR:0.0000 - train_loss: 1.663Step 6241/9637 - LR:0.0000 - train_loss: 1.672Step 6251/9637 - LR:0.0000 - train_loss: 1.648Step 6261/9637 - LR:0.0000 - train_loss: 1.657Step 6271/9637 - LR:0.0000 - train_loss: 1.655Step 6281/9637 - LR:0.0000 - train_loss: 1.633Step 6291/9637 - LR:0.0000 - train_loss: 1.652Step 6301/9637 - LR:0.0000 - train_loss: 1.660Step 6311/9637 - LR:0.0000 - train_loss: 1.655Step 6321/9637 - LR:0.0000 - train_loss: 1.665Step 6331/9637 - LR:0.0000 - train_loss: 1.669Step 6341/9637 - LR:0.0000 - train_loss: 1.657Step 6351/9637 - LR:0.0000 - train_loss: 1.677Step 6361/9637 - LR:0.0000 - train_loss: 1.655Step 6371/9637 - LR:0.0000 - train_loss: 1.640Step 6381/9637 - LR:0.0000 - train_loss: 1.651Step 6391/9637 - LR:0.0000 - train_loss: 1.658Step 6401/9637 - LR:0.0000 - train_loss: 1.661Step 6411/9637 - LR:0.0000 - train_loss: 1.653Step 6421/9637 - LR:0.0000 - train_loss: 1.666Step 6431/9637 - LR:0.0000 - train_loss: 1.637Step 6441/9637 - LR:0.0000 - train_loss: 1.636Step 6451/9637 - LR:0.0000 - train_loss: 1.626Step 6461/9637 - LR:0.0000 - train_loss: 1.675Step 6471/9637 - LR:0.0000 - train_loss: 1.654Step 6481/9637 - LR:0.0000 - train_loss: 1.650Step 6491/9637 - LR:0.0000 - train_loss: 1.640Step 6501/9637 - LR:0.0000 - train_loss: 1.659Step 6511/9637 - LR:0.0000 - train_loss: 1.660Step 6521/9637 - LR:0.0000 - train_loss: 1.639Step 6531/9637 - LR:0.0000 - train_loss: 1.648Step 6541/9637 - LR:0.0000 - train_loss: 1.628Step 6551/9637 - LR:0.0000 - train_loss: 1.611Step 6561/9637 - LR:0.0000 - train_loss: 1.649Step 6571/9637 - LR:0.0000 - train_loss: 1.644Step 6581/9637 - LR:0.0000 - train_loss: 1.667Step 6591/9637 - LR:0.0000 - train_loss: 1.633Step 6601/9637 - LR:0.0000 - train_loss: 1.650Step 6611/9637 - LR:0.0000 - train_loss: 1.645Step 6621/9637 - LR:0.0000 - train_loss: 1.635Step 6631/9637 - LR:0.0000 - train_loss: 1.631Step 6641/9637 - LR:0.0000 - train_loss: 1.640Step 6651/9637 - LR:0.0000 - train_loss: 1.632Step 6661/9637 - LR:0.0000 - train_loss: 1.625Step 6671/9637 - LR:0.0000 - train_loss: 1.643Step 6681/9637 - LR:0.0000 - train_loss: 1.640Step 6691/9637 - LR:0.0000 - train_loss: 1.596Step 6701/9637 - LR:0.0000 - train_loss: 1.617Step 6711/9637 - LR:0.0000 - train_loss: 1.604Step 6721/9637 - LR:0.0000 - train_loss: 1.615Step 6731/9637 - LR:0.0000 - train_loss: 1.629Step 6741/9637 - LR:0.0000 - train_loss: 1.625Step 6751/9637 - LR:0.0000 - train_loss: 1.599Step 6761/9637 - LR:0.0000 - train_loss: 1.616Step 6771/9637 - LR:0.0000 - train_loss: 1.653Step 6781/9637 - LR:0.0000 - train_loss: 1.620Step 6791/9637 - LR:0.0000 - train_loss: 1.611Step 6801/9637 - LR:0.0000 - train_loss: 1.646Step 6811/9637 - LR:0.0000 - train_loss: 1.609Step 6821/9637 - LR:0.0000 - train_loss: 1.594Step 6831/9637 - LR:0.0000 - train_loss: 1.593Step 6841/9637 - LR:0.0000 - train_loss: 1.619Step 6851/9637 - LR:0.0000 - train_loss: 1.614Step 6861/9637 - LR:0.0000 - train_loss: 1.609Step 6871/9637 - LR:0.0000 - train_loss: 1.592Step 6881/9637 - LR:0.0000 - train_loss: 1.625Step 6891/9637 - LR:0.0000 - train_loss: 1.607Step 6901/9637 - LR:0.0000 - train_loss: 1.587Step 6911/9637 - LR:0.0000 - train_loss: 1.602Step 6921/9637 - LR:0.0000 - train_loss: 1.636Step 6931/9637 - LR:0.0000 - train_loss: 1.609Step 6941/9637 - LR:0.0000 - train_loss: 1.579Step 6951/9637 - LR:0.0000 - train_loss: 1.580Step 6961/9637 - LR:0.0000 - train_loss: 1.598Step 6971/9637 - LR:0.0000 - train_loss: 1.622Step 6981/9637 - LR:0.0000 - train_loss: 1.605Step 6991/9637 - LR:0.0000 - train_loss: 1.639Step 7001/9637 - LR:0.0000 - train_loss: 1.597Step 7011/9637 - LR:0.0000 - train_loss: 1.568Step 7021/9637 - LR:0.0000 - train_loss: 1.597Step 7031/9637 - LR:0.0000 - train_loss: 1.590Step 7041/9637 - LR:0.0000 - train_loss: 1.591Step 7051/9637 - LR:0.0000 - train_loss: 1.580Step 7061/9637 - LR:0.0000 - train_loss: 1.579Step 7071/9637 - LR:0.0000 - train_loss: 1.585Step 7081/9637 - LR:0.0000 - train_loss: 1.629Step 7091/9637 - LR:0.0000 - train_loss: 1.587Step 7101/9637 - LR:0.0000 - train_loss: 1.591Step 7111/9637 - LR:0.0000 - train_loss: 1.603Step 7121/9637 - LR:0.0000 - train_loss: 1.592Step 7131/9637 - LR:0.0000 - train_loss: 1.572Step 7141/9637 - LR:0.0000 - train_loss: 1.609Step 7151/9637 - LR:0.0000 - train_loss: 1.588Step 7161/9637 - LR:0.0000 - train_loss: 1.568Step 7171/9637 - LR:0.0000 - train_loss: 1.592Step 7181/9637 - LR:0.0000 - train_loss: 1.575Step 7191/9637 - LR:0.0000 - train_loss: 1.571Step 7201/9637 - LR:0.0000 - train_loss: 1.569Step 7211/9637 - LR:0.0000 - train_loss: 1.590Step 7221/9637 - LR:0.0000 - train_loss: 1.578Step 7231/9637 - LR:0.0000 - train_loss: 1.615Step 7241/9637 - LR:0.0000 - train_loss: 1.566Step 7251/9637 - LR:0.0000 - train_loss: 1.594Step 7261/9637 - LR:0.0000 - train_loss: 1.585Step 7271/9637 - LR:0.0000 - train_loss: 1.578Step 7281/9637 - LR:0.0000 - train_loss: 1.586Step 7291/9637 - LR:0.0000 - train_loss: 1.575Step 7301/9637 - LR:0.0000 - train_loss: 1.559Step 7311/9637 - LR:0.0000 - train_loss: 1.611Step 7321/9637 - LR:0.0000 - train_loss: 1.578Step 7331/9637 - LR:0.0000 - train_loss: 1.557Step 7341/9637 - LR:0.0000 - train_loss: 1.585Step 7351/9637 - LR:0.0000 - train_loss: 1.552Step 7361/9637 - LR:0.0000 - train_loss: 1.581Step 7371/9637 - LR:0.0000 - train_loss: 1.575Step 7381/9637 - LR:0.0000 - train_loss: 1.547Step 7391/9637 - LR:0.0000 - train_loss: 1.541Step 7401/9637 - LR:0.0000 - train_loss: 1.546Step 7411/9637 - LR:0.0000 - train_loss: 1.560Step 7421/9637 - LR:0.0000 - train_loss: 1.562Step 7431/9637 - LR:0.0000 - train_loss: 1.571Step 7441/9637 - LR:0.0000 - train_loss: 1.551Step 7451/9637 - LR:0.0000 - train_loss: 1.554Step 7461/9637 - LR:0.0000 - train_loss: 1.556Step 7471/9637 - LR:0.0000 - train_loss: 1.551Step 7481/9637 - LR:0.0000 - train_loss: 1.567Step 7491/9637 - LR:0.0000 - train_loss: 1.553Step 7501/9637 - LR:0.0000 - train_loss: 1.553Step 7511/9637 - LR:0.0000 - train_loss: 1.575Step 7521/9637 - LR:0.0000 - train_loss: 1.547Step 7531/9637 - LR:0.0000 - train_loss: 1.558Step 7541/9637 - LR:0.0000 - train_loss: 1.543Step 7551/9637 - LR:0.0000 - train_loss: 1.555Step 7561/9637 - LR:0.0000 - train_loss: 1.564Step 7571/9637 - LR:0.0000 - train_loss: 1.553Step 7581/9637 - LR:0.0000 - train_loss: 1.540Step 7591/9637 - LR:0.0000 - train_loss: 1.539Step 7601/9637 - LR:0.0000 - train_loss: 1.519Step 7611/9637 - LR:0.0000 - train_loss: 1.519Step 7621/9637 - LR:0.0000 - train_loss: 1.558Step 7631/9637 - LR:0.0000 - train_loss: 1.530Step 7641/9637 - LR:0.0000 - train_loss: 1.547Step 7651/9637 - LR:0.0000 - train_loss: 1.558Step 7661/9637 - LR:0.0000 - train_loss: 1.533Step 7671/9637 - LR:0.0000 - train_loss: 1.541Step 7681/9637 - LR:0.0000 - train_loss: 1.548Step 7691/9637 - LR:0.0000 - train_loss: 1.533Step 7701/9637 - LR:0.0000 - train_loss: 1.551Step 7711/9637 - LR:0.0000 - train_loss: 1.531Step 7721/9637 - LR:0.0000 - train_loss: 1.522Step 7731/9637 - LR:0.0000 - train_loss: 1.546Step 7741/9637 - LR:0.0000 - train_loss: 1.538Step 7751/9637 - LR:0.0000 - train_loss: 1.526Step 7761/9637 - LR:0.0000 - train_loss: 1.561Step 7771/9637 - LR:0.0000 - train_loss: 1.520Step 7781/9637 - LR:0.0000 - train_loss: 1.527Step 7791/9637 - LR:0.0000 - train_loss: 1.540Step 7801/9637 - LR:0.0000 - train_loss: 1.529Step 7811/9637 - LR:0.0000 - train_loss: 1.531Step 7821/9637 - LR:0.0000 - train_loss: 1.555Step 7831/9637 - LR:0.0000 - train_loss: 1.511Step 7841/9637 - LR:0.0000 - train_loss: 1.555Step 7851/9637 - LR:0.0000 - train_loss: 1.540Step 7861/9637 - LR:0.0000 - train_loss: 1.545Step 7871/9637 - LR:0.0000 - train_loss: 1.526Step 7881/9637 - LR:0.0000 - train_loss: 1.515Step 7891/9637 - LR:0.0000 - train_loss: 1.512Step 7901/9637 - LR:0.0000 - train_loss: 1.543Step 7911/9637 - LR:0.0000 - train_loss: 1.499Step 7921/9637 - LR:0.0000 - train_loss: 1.511Step 7931/9637 - LR:0.0000 - train_loss: 1.527Step 7941/9637 - LR:0.0000 - train_loss: 1.488Step 7951/9637 - LR:0.0000 - train_loss: 1.515Step 7961/9637 - LR:0.0000 - train_loss: 1.538Step 7971/9637 - LR:0.0000 - train_loss: 1.509Step 7981/9637 - LR:0.0000 - train_loss: 1.537Step 7991/9637 - LR:0.0000 - train_loss: 1.510Step 8001/9637 - LR:0.0000 - train_loss: 1.530Step 8011/9637 - LR:0.0000 - train_loss: 1.499Step 8021/9637 - LR:0.0000 - train_loss: 1.538Step 8031/9637 - LR:0.0000 - train_loss: 1.539Step 8041/9637 - LR:0.0000 - train_loss: 1.495Step 8051/9637 - LR:0.0000 - train_loss: 1.529Step 8061/9637 - LR:0.0000 - train_loss: 1.519Step 8071/9637 - LR:0.0000 - train_loss: 1.516Step 8081/9637 - LR:0.0000 - train_loss: 1.494Step 8091/9637 - LR:0.0000 - train_loss: 1.527Step 8101/9637 - LR:0.0000 - train_loss: 1.518Step 8111/9637 - LR:0.0000 - train_loss: 1.521Step 8121/9637 - LR:0.0000 - train_loss: 1.533Step 8131/9637 - LR:0.0000 - train_loss: 1.493Step 8141/9637 - LR:0.0000 - train_loss: 1.513Step 8151/9637 - LR:0.0000 - train_loss: 1.494Step 8161/9637 - LR:0.0000 - train_loss: 1.497Step 8171/9637 - LR:0.0000 - train_loss: 1.516Step 8181/9637 - LR:0.0000 - train_loss: 1.526Step 8191/9637 - LR:0.0000 - train_loss: 1.514Step 8201/9637 - LR:0.0000 - train_loss: 1.514Step 8211/9637 - LR:0.0000 - train_loss: 1.505Step 8221/9637 - LR:0.0000 - train_loss: 1.480Step 8231/9637 - LR:0.0000 - train_loss: 1.501Step 8241/9637 - LR:0.0000 - train_loss: 1.507Step 8251/9637 - LR:0.0000 - train_loss: 1.503Step 8261/9637 - LR:0.0000 - train_loss: 1.481Step 8271/9637 - LR:0.0000 - train_loss: 1.507Step 8281/9637 - LR:0.0000 - train_loss: 1.500Step 8291/9637 - LR:0.0000 - train_loss: 1.514Step 8301/9637 - LR:0.0000 - train_loss: 1.508Step 8311/9637 - LR:0.0000 - train_loss: 1.505Step 8321/9637 - LR:0.0000 - train_loss: 1.481Step 8331/9637 - LR:0.0000 - train_loss: 1.474Step 8341/9637 - LR:0.0000 - train_loss: 1.501Step 8351/9637 - LR:0.0000 - train_loss: 1.477Step 8361/9637 - LR:0.0000 - train_loss: 1.469Step 8371/9637 - LR:0.0000 - train_loss: 1.476Step 8381/9637 - LR:0.0000 - train_loss: 1.479Step 8391/9637 - LR:0.0000 - train_loss: 1.501Step 8401/9637 - LR:0.0000 - train_loss: 1.480Step 8411/9637 - LR:0.0000 - train_loss: 1.506Step 8421/9637 - LR:0.0000 - train_loss: 1.462Step 8431/9637 - LR:0.0000 - train_loss: 1.498Step 8441/9637 - LR:0.0000 - train_loss: 1.491Step 8451/9637 - LR:0.0000 - train_loss: 1.519Step 8461/9637 - LR:0.0000 - train_loss: 1.493Step 8471/9637 - LR:0.0000 - train_loss: 1.493Step 8481/9637 - LR:0.0000 - train_loss: 1.494Step 8491/9637 - LR:0.0000 - train_loss: 1.507Step 8501/9637 - LR:0.0000 - train_loss: 1.510Step 8511/9637 - LR:0.0000 - train_loss: 1.480Step 8521/9637 - LR:0.0000 - train_loss: 1.464Step 8531/9637 - LR:0.0000 - train_loss: 1.493Step 8541/9637 - LR:0.0000 - train_loss: 1.502Step 8551/9637 - LR:0.0000 - train_loss: 1.493Step 8561/9637 - LR:0.0000 - train_loss: 1.487Step 8571/9637 - LR:0.0000 - train_loss: 1.481Step 8581/9637 - LR:0.0000 - train_loss: 1.494Step 8591/9637 - LR:0.0000 - train_loss: 1.494Step 8601/9637 - LR:0.0000 - train_loss: 1.485Step 8611/9637 - LR:0.0000 - train_loss: 1.470Step 8621/9637 - LR:0.0000 - train_loss: 1.471Step 8631/9637 - LR:0.0000 - train_loss: 1.511Step 8641/9637 - LR:0.0000 - train_loss: 1.497Step 8651/9637 - LR:0.0000 - train_loss: 1.501Step 8661/9637 - LR:0.0000 - train_loss: 1.439Step 8671/9637 - LR:0.0000 - train_loss: 1.465Step 8681/9637 - LR:0.0000 - train_loss: 1.466Step 8691/9637 - LR:0.0000 - train_loss: 1.482Step 8701/9637 - LR:0.0000 - train_loss: 1.478Step 8711/9637 - LR:0.0000 - train_loss: 1.480Step 8721/9637 - LR:0.0000 - train_loss: 1.424Step 8731/9637 - LR:0.0000 - train_loss: 1.471Step 8741/9637 - LR:0.0000 - train_loss: 1.451Step 8751/9637 - LR:0.0000 - train_loss: 1.467Step 8761/9637 - LR:0.0000 - train_loss: 1.464Step 8771/9637 - LR:0.0000 - train_loss: 1.479Step 8781/9637 - LR:0.0000 - train_loss: 1.461Step 8791/9637 - LR:0.0000 - train_loss: 1.453Step 8801/9637 - LR:0.0000 - train_loss: 1.425Step 8811/9637 - LR:0.0000 - train_loss: 1.479Step 8821/9637 - LR:0.0000 - train_loss: 1.451Step 8831/9637 - LR:0.0000 - train_loss: 1.472Step 8841/9637 - LR:0.0000 - train_loss: 1.470Step 8851/9637 - LR:0.0000 - train_loss: 1.428Step 8861/9637 - LR:0.0000 - train_loss: 1.458Step 8871/9637 - LR:0.0000 - train_loss: 1.452Step 8881/9637 - LR:0.0000 - train_loss: 1.458Step 8891/9637 - LR:0.0000 - train_loss: 1.450Step 8901/9637 - LR:0.0000 - train_loss: 1.467Step 8911/9637 - LR:0.0000 - train_loss: 1.463Step 8921/9637 - LR:0.0000 - train_loss: 1.494Step 8931/9637 - LR:0.0000 - train_loss: 1.459Step 8941/9637 - LR:0.0000 - train_loss: 1.442Step 8951/9637 - LR:0.0000 - train_loss: 1.481Step 8961/9637 - LR:0.0000 - train_loss: 1.436Step 8971/9637 - LR:0.0000 - train_loss: 1.452Step 8981/9637 - LR:0.0000 - train_loss: 1.444Step 8991/9637 - LR:0.0000 - train_loss: 1.434Step 9001/9637 - LR:0.0000 - train_loss: 1.438Step 9011/9637 - LR:0.0000 - train_loss: 1.436Step 9021/9637 - LR:0.0000 - train_loss: 1.432Step 9031/9637 - LR:0.0000 - train_loss: 1.432Step 9041/9637 - LR:0.0000 - train_loss: 1.444Step 9051/9637 - LR:0.0000 - train_loss: 1.439Step 9061/9637 - LR:0.0000 - train_loss: 1.420Step 9071/9637 - LR:0.0000 - train_loss: 1.458Step 9081/9637 - LR:0.0000 - train_loss: 1.458Step 9091/9637 - LR:0.0000 - train_loss: 1.458Step 9101/9637 - LR:0.0000 - train_loss: 1.446Step 9111/9637 - LR:0.0000 - train_loss: 1.443Step 9121/9637 - LR:0.0000 - train_loss: 1.451Step 9131/9637 - LR:0.0000 - train_loss: 1.454Step 9141/9637 - LR:0.0000 - train_loss: 1.448Step 9151/9637 - LR:0.0000 - train_loss: 1.439Step 9161/9637 - LR:0.0000 - train_loss: 1.439Step 9171/9637 - LR:0.0000 - train_loss: 1.445Step 9181/9637 - LR:0.0000 - train_loss: 1.415Step 9191/9637 - LR:0.0000 - train_loss: 1.436Step 9201/9637 - LR:0.0000 - train_loss: 1.455Step 9211/9637 - LR:0.0000 - train_loss: 1.430Step 9221/9637 - LR:0.0000 - train_loss: 1.425Step 9231/9637 - LR:0.0000 - train_loss: 1.439Step 9241/9637 - LR:0.0000 - train_loss: 1.427Step 9251/9637 - LR:0.0000 - train_loss: 1.422Step 9261/9637 - LR:0.0000 - train_loss: 1.410Step 9271/9637 - LR:0.0000 - train_loss: 1.439Step 9281/9637 - LR:0.0000 - train_loss: 1.424Step 9291/9637 - LR:0.0000 - train_loss: 1.413Step 9301/9637 - LR:0.0000 - train_loss: 1.446Step 9311/9637 - LR:0.0000 - train_loss: 1.447Step 9321/9637 - LR:0.0000 - train_loss: 1.422Step 9331/9637 - LR:0.0000 - train_loss: 1.422Step 9341/9637 - LR:0.0000 - train_loss: 1.422Step 9351/9637 - LR:0.0000 - train_loss: 1.414Step 9361/9637 - LR:0.0000 - train_loss: 1.418Step 9371/9637 - LR:0.0000 - train_loss: 1.435Step 9381/9637 - LR:0.0000 - train_loss: 1.435Step 9391/9637 - LR:0.0000 - train_loss: 1.413Step 9401/9637 - LR:0.0000 - train_loss: 1.420Step 9411/9637 - LR:0.0000 - train_loss: 1.424Step 9421/9637 - LR:0.0000 - train_loss: 1.422Step 9431/9637 - LR:0.0000 - train_loss: 1.428Step 9441/9637 - LR:0.0000 - train_loss: 1.431Step 9451/9637 - LR:0.0000 - train_loss: 1.429Step 9461/9637 - LR:0.0000 - train_loss: 1.422Step 9471/9637 - LR:0.0000 - train_loss: 1.436Step 9481/9637 - LR:0.0000 - train_loss: 1.398Step 9491/9637 - LR:0.0000 - train_loss: 1.426Step 9501/9637 - LR:0.0000 - train_loss: 1.409Step 9511/9637 - LR:0.0000 - train_loss: 1.400Step 9521/9637 - LR:0.0000 - train_loss: 1.406Step 9531/9637 - LR:0.0000 - train_loss: 1.422Step 9541/9637 - LR:0.0000 - train_loss: 1.401Step 9551/9637 - LR:0.0000 - train_loss: 1.404Step 9561/9637 - LR:0.0000 - train_loss: 1.402Step 9571/9637 - LR:0.0000 - train_loss: 1.412Step 9581/9637 - LR:0.0000 - train_loss: 1.432Step 9591/9637 - LR:0.0000 - train_loss: 1.406Step 9601/9637 - LR:0.0000 - train_loss: 1.428Step 9611/9637 - LR:0.0000 - train_loss: 1.428Step 9621/9637 - LR:0.0000 - train_loss: 1.426Step 9631/9637 - LR:0.0000 - train_loss: 1.408Step 9637/9637 - LR:0.0000 - train_loss: 1.375
exit train!
Once upon a time, Tom is very hungry, but he doesn't give up. He is a bit of the difficult. He wipes up the drople of sand off, both of the other ones stopped and started to clean up. "Can you help us?" asked some of the parents. He had an idea. He helped them both onto the end of the day. He and the children worked together to clean up the rest of the day. 

I like apple, but Lily loves the big, clear eye. They go to a bench or on the table. They are both calming down with their minnch help! 

Once upon a time, there is a boy named Tom. <|endofied,  ⁇  Chinning is a fun tricky spot. He was very thankful! 

Once upon a time, there is a girl named Lily. One day, she was feeling annoyre. She started to eat the big, juicy snowballs he has ever hated. The moral of the story is ⁇  Don't be mean or even try to hurt you. 

I love the monkey, but all of it and watched, "thumphewole. Mildy and Foxy had made a big, new start. No matter how hard the bad dog had been. A big, deep mouth could gets of money. Both and the young boys had been able to keep the big brother. They will never be afraid of a bear or a normal shrimp." The big brother said "I'm sorry. It was an important lesson to listen to you - don't judge you by your youths!" The brothers were very scared. They started to weep, but the big brother said, "I will obey the judge. I will make you the same! Come on, stay with me". The two of them worked together to free the big, long fight. They both reached the top and It was a good plan. They decided to stay together and not shout or play. Then they both had to run away and stay safe inside. They never wanted the big dog to go explore.Tim and Beth were very sad. They never got to cross the street again. 

Once upon a time, there is a monkey in the park. <|endofacy, a little girl was looking for something shiny in the blanket. She saw the big, bright pink shrugs of beautiful things. She was so excited that she forgot to look at the sky and enjoyed the feeling of feeling. The two friends spent the rest of the day playing and smiling about the importance of the Phymiration. They enjoyed the rest of their time together in the calm while they had so much fun. 

Once upon a time, the sun is dimmed. They welcomed the rest of their arms and yelled, guarding each other. They decided to go for an adventure that would be just as important as the lazy and lazy day had been done. 

Once upon a time, the water is dirty. Goy,  ⁇ ning in a tired and fiter voice, he was filled with joy and joy and happiness. <|endoficiving first kids became best friends. They worked hard and cheered for their hard work. Necrate of the actions, they helped to keep the big thle safe from the big bullywork. The moral of the story is ⁇  No matter how hard or practory, life can get separate and it won't have anyone else in it. 

Once upon a time, sophia won the first prize in the competition. James loved looking at the clare. He took the dog under the bed, munching on the wreck and splashing around the rocks. He was so excited and kept scraming the difference. The moral of the story is ⁇  Do not be too small or just a small pieces. Honey is a bit of energy or a run, or too fast. Hards around thewh and the mayorty. Whenever Becky never had forgotten, every exchoder had to do. This was a lot of sculpture, but they weren't paying. At the end of their journey, Honey said good deck of herself. "Goodbye, Honey!" she said. "Goodbye, friend. I'll never forget a lazy bel again." Honey was so proud of himself. He had done it! 

Once upon a time, there was a little girl named Lucy. She had a pet cat named Tom. Tom was so excited that he had been practicing a few hours. He knew that she could do it, so he crossed the street one more time. The moral of the story is that everyone should have worked hard for a while. Phail is something that we can always eat over ourselves. 

Once upon a time, there was a little brown dog named Spot. Max laughed and thought it was a fun game. He moved around the house and started to count. It was the start of him and other children! <|endoth people now realised what seemed like this game. They would always remember the special spot and the small girl names, but to the end. 

Once upon a time, there was a little boy named Tom. He felt a bit, wiggled and shorees. He was so excited that he wanted to have a rest and he started his march. It was so easy that before he knew he could do it! The end. 

Once upon a time, there was a big whale. Louise was so excited and shouted on the fake los. He was so excited and laughed, but when he touched the ground, he felt something moving. His teacher looked at him and smiled. "That's what you do. You're a very good!" The naughty little boy nodded and continued to look at the children. He felt very happy and excited. The lively children laughed and smiled. From that moment on, they could always find a way to have fun and take care of their bodies. 

Once upon a time, there was a perfect spot. Do you think of these special things in the park - they might be found! The end. <|endofused by the west, but we can continue to always be humble and not do anything about the big, cheap thing they all find. It is the end of the story that we have to work hard to keep it clean and healthy. 

Once upon a time, but they will save your goals. The girl was biting them, clareendly on a yawn. Anthis's there's a huge sense of what Daisy and his pully had been doing all about the scary and bad guy. 

Once that they are the most important thing ever had ever happened. <|endoris, trying to help people get off. Before long, they had to wait for their turn. The end. 

Tim and Lily were playing in the park. <|endofied was the size they's where they come from each other. They got a small box, and enjoyed their jazz. 

Tom had a coin that he liked very much. Tommy learned that surprises can be good and that some things can be disgusting. He cheered for those who use them to be. From that day on, they worked together to help each other and always put their things away. They worked hard and conded and confed the there force. 

Tim and Mia like to play in the backyard. Terry was so happy and happy that they shared the magical friendship and shincle. <|endoftext|endoftext|endofil and Phinne, there were two friends, a bear and a rabbit. Every day they would get up and down, next time they could stretch their heads together. One day, the bear and their little brothers went for a walk. One little boy was very hungry. Suddenly, Tom could hear the cries! He was so surprised and still very hungry. Suddenly, he saw a bag of berries scattering out of the ground. The bear was so excited and ran around the berries, and soon it was full! The bear and his friends started running around the garden with the big, round berries. But soon the bear got tired and they both started to get very tired. They knew that the bear left was sleeping in the same spot they had ever been to before. The bear and his friends were so tired but happy. They put the small berry in their restance and waited for it to come back. The bear and his friends were so happy when they heard the story. It was so lucky that they were so hungry! They all had a great time and were happy ever. 

Tom and Mia went to the zoo with Mom and Dad. He and Sara did not believe that this time was gone and they both felt so happy to start on the zoom. They did not stop for a while, but soon the sun started to set and the little girl and her brothers were getting tired. They lay down, closed their eyes and took a nap. They dreamed of more fun than ever before. 

Anna liked to speak to her toys. He had said, "Spating is not able to keep something from the mill!" Jake nodded in a drop and smiled. He knew he was still sad and wanted to keep it a bit for himself. He smiled, glad that he had helped the people and it made him happy. 

Lily was playing with her doll in the garden. <|endofied how the apple-host is an amazing sight. As the sun began to set, it was feeling of being shiny and newse. But soon, one of them came to a more helpful side. The moral of the story is that being flexible and determined could make the most continue. Being adventurous and listening will always be And sure to be kind whenever you can be harmless. 

Tim likes to talk about politics. hinning?" <|endofied. His tiny clothes did not move anymore. The elderly lady could not help but she was still angry and sad. She looked around to see who was eating too. The children had to stop pushing the tears. They looked at each other and smiled. "Well, you did that! You're doing a good job!" they said. The moral of the story is ⁇  don't judge them by their appearance. Sharing things can be better if you use them. 

Sophia never eats breakfast. < of the cost people in the finish line. The end. <|endofidend smiled, knowing that this would be a good. <|endofied overhery-stather were hungry. He felt saveered and sorry to the people that were kind and caring. The end. 

Lucy tell a weird story. The man was so proud of his plan that they did not be safe at all. Herencoys were sorry and scolded him for his hard work. He was so ashamed that he had been redic and unherpers. He walked back to the park, feeling very sad. 

Lucy and Lily are playing computer games. < little boys quickly shrugged. "It's! We can all go. Pher bridge is a big tree and it might make us sick!" The boys were scared and started running away. Tommy was sad and his heart scruded. In the end, they all went back to their game. They had sboving his fear and enjoying the rest of their day. 

checkpoint saved!
Executing command >>>> 
   srun --pty -c 10 -p makkapakka --export=ALL --gpus=5  ./run.sh

